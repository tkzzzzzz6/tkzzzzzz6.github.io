<!DOCTYPE html>
<html lang="zh">
  <head>
    
    <meta charset="UTF-8">
    <title>2025-02-15-语义分割 - TK的小站</title>
    <link rel="shortcut icon" href="/static/img/icon.png">
    <link rel="icon" href="/static/img/icon.png" sizes="192x192"/>
    
<link rel="stylesheet" href="/static/kico.css">
<link rel="stylesheet" href="/static/hingle.css">

    
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <meta property="og:site_name" content="TK的小站">
    <meta property="og:title" content="2025-02-15-语义分割"/>
    
    <style>body:before{ content: ''; background-image: url(https://api.paugram.com/wallpaper?source=gh) }</style>
    
<meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="TK的小站" type="application/atom+xml">
</head>

  <body>
    <header>
    <div class="head-title">
        <h4>TK的小站</h4>
    </div>
    <div class="head-action">
        <div class="toggle-btn"></div>
        <div class="light-btn"></div>
        <div class="search-btn"></div>
    </div>
    <form class="head-search" method="post">
        <input type="text" name="s" placeholder="搜索什么？">
    </form>
    <nav class="head-menu">
        <a href="/">首页</a>
        <div class="has-child">
            <a href>分类</a>
            <div class="sub-menu">
                
            </div>
        </div>
        
            <a href="/about">关于我</a>
        
            <a href="/friends">朋友们</a>
        
            <a href="/tools">工具推荐</a>
        
    </nav>
</header>

    <main>
    <div class="wrap min">
        <section class="post-title">
            <h2>2025-02-15-语义分割</h2>
            <div class="post-meta">
                <time class="date">2025.02.15</time>
            
            </div>
        </section>
        <article class="post-content">
        
            <blockquote>这篇文章上次修改于 229 天前，可能其部分内容已经发生变化，如有疑问可询问作者。</blockquote>
        
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在开始这篇文章之前，我们得首先弄明白，什么是图像分割？</p>
<p>我们知道一个图像只不过是许多像素的集合。图像分割分类是对图像中属于特定类别的像素进行分类的过程，即像素级别的下游任务。因此图像分割简单来说就是按像素进行分类的问题。</p>
<p>传统的图像分割算法均是基于灰度值的不连续和相似的性质。而基于深度学习的图像分割技术则是利用卷积神经网络，来理解图像中的每个像素所代表的真实世界物体，这在以前是难以想象的。</p>
<p><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/1740235822031FRBrbtq8Zogp1oxNSIhcx7Z6nVb.png" alt="1740235822031FRBrbtq8Zogp1oxNSIhcx7Z6nVb.png"></p>
<h1 id="语义分割（Semantic-Segmentation）"><a href="#语义分割（Semantic-Segmentation）" class="headerlink" title="语义分割（Semantic Segmentation）"></a><strong>语义分割（Semantic Segmentation）</strong></h1><h2 id="定义"><a href="#定义" class="headerlink" title="** 定义**"></a>** 定义**</h2><p>“语义”是个很抽象的概念，在 2D 图像领域，每个像素点作为最小单位，它的像素值代表的就是一个特征，即“语义”信息。语义分割会为图像中的每个像素分配一个类别，但是同一类别之间的对象不会区分。而实例分割，只对特定的物体进行分类。这看起来与目标检测相似，不同的是目标检测输出目标的边界框和类别，实例分割输出的是目标的 Mask 和类别。具体而言，语义分割的目的是为了从像素级别理解图像的内容，并为图像中的每个像素分配一个对象类。</p>
<p>语义分割是一种将图像中的每个像素分配给特定类别的技术。其目标是识别图像中存在的各种对象和背景，并为每个像素分配相应的类别标签。例如，将图像中的像素划分为人、树、草地和天空等不同区域。是图像处理和机器视觉一个重要分支。与分类任务不同，语义分割需要判断图像每个像素点的类别，进行精确分割。语义分割目前在自动驾驶、自动抠图、医疗影像等领域有着比较广泛的应用。</p>
<h2 id="特点"><a href="#特点" class="headerlink" title="** 特点**"></a>** 特点**</h2><ul>
<li>提供精确的像素级分类，有助于深入理解图像内容。</li>
<li>无法区分同一类别中的不同实例。</li>
</ul>
<h2 id="语义分割的应用"><a href="#语义分割的应用" class="headerlink" title="** 语义分割的应用**"></a>** 语义分割的应用**</h2><p>语义分割在多个领域有广泛应用：</p>
<ul>
<li><strong>自动驾驶</strong>：用于道路、车辆和行人的识别。</li>
<li><strong>医学成像</strong>：用于组织和器官的分割。</li>
<li><strong>卫星遥感</strong>：用于土地覆盖分类。</li>
</ul>
<h2 id="常见模型"><a href="#常见模型" class="headerlink" title="** 常见模型**"></a>** 常见模型**</h2><h3 id="FCN（Fully-Convolutional-Network）"><a href="#FCN（Fully-Convolutional-Network）" class="headerlink" title="FCN（Fully Convolutional Network）"></a><strong>FCN（Fully Convolutional Network）</strong></h3><ul>
<li><strong>优点</strong>：简单易用，但是现在已经很少使用了,但它的历史贡献不可忽视。</li>
<li><strong>缺点</strong>：分割精度较低，可能无法很好地处理细节。</li>
</ul>
<h4 id="提出初衷"><a href="#提出初衷" class="headerlink" title="提出初衷"></a>提出初衷</h4><p><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/1740236704772Z5SNbToLOosLf9xBvllcevjVnEe.png" alt="1740236704772Z5SNbToLOosLf9xBvllcevjVnEe.png"><br>FCN（全卷积网络）模型的初衷是为了解决传统卷积神经网络（CNN）在语义分割任务中的局限性。具体而言，传统 CNN 使用全连接层进行分类，这会丢失图像的空间位置信息，导致其不适合像素级的预测任务。FCN 的核心动机包括：</p>
<ol>
<li><strong>实现端到端的像素级预测</strong>：FCN 通过将全连接层替换为卷积层，使得网络能够接受任意尺寸的输入图像，并输出与输入尺寸相同的像素级预测结果。</li>
<li><strong>保留空间信息</strong>：取消全连接层后，FCN 能够保留图像的空间位置信息，从而更好地适应语义分割任务。</li>
<li><strong>提高分割效率和精度</strong>：通过引入反卷积层（上采样层）和跳跃连接（Skip Connections），FCN 能够融合不同深度的特征，兼顾全局语义信息和局部细节，从而提升分割精度。</li>
<li><strong>利用预训练模型加速训练</strong>：FCN 可以基于预训练的分类模型（如 AlexNet、VGG 等）进行微调，从而显著加速训练过程并提高模型性能。</li>
</ol>
<h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/1740236686503VcqtbHWWQoRtJIxgy6bconZQnHc.png" alt="1740236686503VcqtbHWWQoRtJIxgy6bconZQnHc.png"><br>通常 CNN 网络在卷积层之后会接上若干个全连接层, 将卷积层产生的特征图(feature map)映射成一个固定长度的特征向量。以 AlexNet 为代表的经典 CNN 结构适合于图像级的分类和回归任务，因为它们最后都期望得到整个输入图像的一个数值描述（概率）。<br>FCN 对图像进行像素级的分类，从而解决了语义级别的图像分割（semantic segmentation）问题。与经典的 CNN 在卷积层之后使用全连接层得到固定长度的特征向量进行分类（全连接层 ＋softmax 输出）不同，FCN 可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的 feature map 进行上采样, 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类。<br><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/1740236781446CxZ6b4zcXo9A12xuNJtcEgA7nfc.png" alt="1740236781446CxZ6b4zcXo9A12xuNJtcEgA7nfc.png"><br>FCN（全卷积网络）为了解决语义分割（semantic segmentation）问题而提出，它对图像进行像素级的分类，能够保留原始输入图像中的空间信息。与传统 CNN 不同，FCN 可以接受任意尺寸的输入图像，并通过以下方式实现像素级分类：</p>
<ol>
<li><strong>去除全连接层</strong>：FCN 将传统 CNN 中的全连接层替换为卷积层，从而保留空间信息。</li>
<li><strong>上采样操作</strong>：使用反卷积层（上采样层）对最后一个卷积层的特征图进行上采样，恢复到与输入图像相同的尺寸。</li>
<li><strong>逐像素分类</strong>：在上采样后的特征图上进行逐像素分类，为每个像素生成类别预测。</li>
</ol>
<blockquote>
<p>Q:<strong>FCN 是如何通过上采样操作恢复特征图的空间分辨率的？</strong></p>
</blockquote>
<h4 id="模型代码"><a href="#模型代码" class="headerlink" title="模型代码"></a>模型代码</h4><h5 id="论文源码"><a href="#论文源码" class="headerlink" title="论文源码"></a>论文源码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> caffe<br><span class="hljs-keyword">from</span> caffe <span class="hljs-keyword">import</span> layers <span class="hljs-keyword">as</span> L, params <span class="hljs-keyword">as</span> P<br><span class="hljs-keyword">from</span> caffe.coord_map <span class="hljs-keyword">import</span> crop<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv_relu</span>(<span class="hljs-params">bottom, nout, ks=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, pad=<span class="hljs-number">1</span></span>):<br>    conv = L.Convolution(bottom, kernel_size=ks, stride=stride,<br>        num_output=nout, pad=pad,<br>        param=[<span class="hljs-built_in">dict</span>(lr_mult=<span class="hljs-number">1</span>, decay_mult=<span class="hljs-number">1</span>), <span class="hljs-built_in">dict</span>(lr_mult=<span class="hljs-number">2</span>, decay_mult=<span class="hljs-number">0</span>)])<br>    <span class="hljs-keyword">return</span> conv, L.ReLU(conv, in_place=<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool</span>(<span class="hljs-params">bottom, ks=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span></span>):<br>    <span class="hljs-keyword">return</span> L.Pooling(bottom, pool=P.Pooling.MAX, kernel_size=ks, stride=stride)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fcn</span>(<span class="hljs-params">split</span>):<br>    n = caffe.NetSpec()<br>    pydata_params = <span class="hljs-built_in">dict</span>(split=split, mean=(<span class="hljs-number">104.00699</span>, <span class="hljs-number">116.66877</span>, <span class="hljs-number">122.67892</span>),<br>            seed=<span class="hljs-number">1337</span>)<br>    <span class="hljs-keyword">if</span> split == <span class="hljs-string">'train'</span>:<br>        pydata_params[<span class="hljs-string">'sbdd_dir'</span>] = <span class="hljs-string">'../data/sbdd/dataset'</span><br>        pylayer = <span class="hljs-string">'SBDDSegDataLayer'</span><br>    <span class="hljs-keyword">else</span>:<br>        pydata_params[<span class="hljs-string">'voc_dir'</span>] = <span class="hljs-string">'../data/pascal/VOC2011'</span><br>        pylayer = <span class="hljs-string">'VOCSegDataLayer'</span><br>    n.data, n.label = L.Python(module=<span class="hljs-string">'voc_layers'</span>, layer=pylayer,<br>            ntop=<span class="hljs-number">2</span>, param_str=<span class="hljs-built_in">str</span>(pydata_params))<br><br>    <span class="hljs-comment"># the base net</span><br>    n.conv1_1, n.relu1_1 = conv_relu(n.data, <span class="hljs-number">64</span>, pad=<span class="hljs-number">100</span>)<br>    n.conv1_2, n.relu1_2 = conv_relu(n.relu1_1, <span class="hljs-number">64</span>)<br>    n.pool1 = max_pool(n.relu1_2)<br><br>    n.conv2_1, n.relu2_1 = conv_relu(n.pool1, <span class="hljs-number">128</span>)<br>    n.conv2_2, n.relu2_2 = conv_relu(n.relu2_1, <span class="hljs-number">128</span>)<br>    n.pool2 = max_pool(n.relu2_2)<br><br>    n.conv3_1, n.relu3_1 = conv_relu(n.pool2, <span class="hljs-number">256</span>)<br>    n.conv3_2, n.relu3_2 = conv_relu(n.relu3_1, <span class="hljs-number">256</span>)<br>    n.conv3_3, n.relu3_3 = conv_relu(n.relu3_2, <span class="hljs-number">256</span>)<br>    n.pool3 = max_pool(n.relu3_3)<br><br>    n.conv4_1, n.relu4_1 = conv_relu(n.pool3, <span class="hljs-number">512</span>)<br>    n.conv4_2, n.relu4_2 = conv_relu(n.relu4_1, <span class="hljs-number">512</span>)<br>    n.conv4_3, n.relu4_3 = conv_relu(n.relu4_2, <span class="hljs-number">512</span>)<br>    n.pool4 = max_pool(n.relu4_3)<br><br>    n.conv5_1, n.relu5_1 = conv_relu(n.pool4, <span class="hljs-number">512</span>)<br>    n.conv5_2, n.relu5_2 = conv_relu(n.relu5_1, <span class="hljs-number">512</span>)<br>    n.conv5_3, n.relu5_3 = conv_relu(n.relu5_2, <span class="hljs-number">512</span>)<br>    n.pool5 = max_pool(n.relu5_3)<br><br>    <span class="hljs-comment"># fully conv</span><br>    n.fc6, n.relu6 = conv_relu(n.pool5, <span class="hljs-number">4096</span>, ks=<span class="hljs-number">7</span>, pad=<span class="hljs-number">0</span>)<br>    n.drop6 = L.Dropout(n.relu6, dropout_ratio=<span class="hljs-number">0.5</span>, in_place=<span class="hljs-literal">True</span>)<br>    n.fc7, n.relu7 = conv_relu(n.drop6, <span class="hljs-number">4096</span>, ks=<span class="hljs-number">1</span>, pad=<span class="hljs-number">0</span>)<br>    n.drop7 = L.Dropout(n.relu7, dropout_ratio=<span class="hljs-number">0.5</span>, in_place=<span class="hljs-literal">True</span>)<br>    n.score_fr = L.Convolution(n.drop7, num_output=<span class="hljs-number">21</span>, kernel_size=<span class="hljs-number">1</span>, pad=<span class="hljs-number">0</span>,<br>        param=[<span class="hljs-built_in">dict</span>(lr_mult=<span class="hljs-number">1</span>, decay_mult=<span class="hljs-number">1</span>), <span class="hljs-built_in">dict</span>(lr_mult=<span class="hljs-number">2</span>, decay_mult=<span class="hljs-number">0</span>)])<br>    n.upscore2 = L.Deconvolution(n.score_fr,<br>        convolution_param=<span class="hljs-built_in">dict</span>(num_output=<span class="hljs-number">21</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>,<br>            bias_term=<span class="hljs-literal">False</span>),<br>        param=[<span class="hljs-built_in">dict</span>(lr_mult=<span class="hljs-number">0</span>)])<br><br>    n.score_pool4 = L.Convolution(n.pool4, num_output=<span class="hljs-number">21</span>, kernel_size=<span class="hljs-number">1</span>, pad=<span class="hljs-number">0</span>,<br>        param=[<span class="hljs-built_in">dict</span>(lr_mult=<span class="hljs-number">1</span>, decay_mult=<span class="hljs-number">1</span>), <span class="hljs-built_in">dict</span>(lr_mult=<span class="hljs-number">2</span>, decay_mult=<span class="hljs-number">0</span>)])<br>    n.score_pool4c = crop(n.score_pool4, n.upscore2)<br>    n.fuse_pool4 = L.Eltwise(n.upscore2, n.score_pool4c,<br>            operation=P.Eltwise.SUM)<br>    n.upscore_pool4 = L.Deconvolution(n.fuse_pool4,<br>        convolution_param=<span class="hljs-built_in">dict</span>(num_output=<span class="hljs-number">21</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>,<br>            bias_term=<span class="hljs-literal">False</span>),<br>        param=[<span class="hljs-built_in">dict</span>(lr_mult=<span class="hljs-number">0</span>)])<br><br>    n.score_pool3 = L.Convolution(n.pool3, num_output=<span class="hljs-number">21</span>, kernel_size=<span class="hljs-number">1</span>, pad=<span class="hljs-number">0</span>,<br>        param=[<span class="hljs-built_in">dict</span>(lr_mult=<span class="hljs-number">1</span>, decay_mult=<span class="hljs-number">1</span>), <span class="hljs-built_in">dict</span>(lr_mult=<span class="hljs-number">2</span>, decay_mult=<span class="hljs-number">0</span>)])<br>    n.score_pool3c = crop(n.score_pool3, n.upscore_pool4)<br>    n.fuse_pool3 = L.Eltwise(n.upscore_pool4, n.score_pool3c,<br>            operation=P.Eltwise.SUM)<br>    n.upscore8 = L.Deconvolution(n.fuse_pool3,<br>        convolution_param=<span class="hljs-built_in">dict</span>(num_output=<span class="hljs-number">21</span>, kernel_size=<span class="hljs-number">16</span>, stride=<span class="hljs-number">8</span>,<br>            bias_term=<span class="hljs-literal">False</span>),<br>        param=[<span class="hljs-built_in">dict</span>(lr_mult=<span class="hljs-number">0</span>)])<br><br>    n.score = crop(n.upscore8, n.data)<br>    n.loss = L.SoftmaxWithLoss(n.score, n.label,<br>            loss_param=<span class="hljs-built_in">dict</span>(normalize=<span class="hljs-literal">False</span>, ignore_label=<span class="hljs-number">255</span>))<br><br>    <span class="hljs-keyword">return</span> n.to_proto()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_net</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">'train.prototxt'</span>, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(<span class="hljs-built_in">str</span>(fcn(<span class="hljs-string">'train'</span>)))<br><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">'val.prototxt'</span>, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(<span class="hljs-built_in">str</span>(fcn(<span class="hljs-string">'seg11valid'</span>)))<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:<br>    make_net()<br></code></pre></td></tr></table></figure>

<h5 id="fcn8-vgg"><a href="#fcn8-vgg" class="headerlink" title="fcn8_vgg"></a>fcn8_vgg</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> absolute_import<br><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> division<br><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function<br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> logging<br><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> ceil<br><span class="hljs-keyword">import</span> sys<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br>VGG_MEAN = [<span class="hljs-number">103.939</span>, <span class="hljs-number">116.779</span>, <span class="hljs-number">123.68</span>]<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FCN8VGG</span>:<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vgg16_npy_path=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-keyword">if</span> vgg16_npy_path <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            path = sys.modules[<span class="hljs-variable language_">self</span>.__class__.__module__].__file__<br>            <span class="hljs-comment"># print path</span><br>            path = os.path.abspath(os.path.join(path, os.pardir))<br>            <span class="hljs-comment"># print path</span><br>            path = os.path.join(path, <span class="hljs-string">"vgg16.npy"</span>)<br>            vgg16_npy_path = path<br>            logging.info(<span class="hljs-string">"Load npy file from '%s'."</span>, vgg16_npy_path)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.isfile(vgg16_npy_path):<br>            logging.error((<span class="hljs-string">"File '%s' not found. Download it from "</span><br>                           <span class="hljs-string">"ftp://mi.eng.cam.ac.uk/pub/mttt2/"</span><br>                           <span class="hljs-string">"models/vgg16.npy"</span>), vgg16_npy_path)<br>            sys.exit(<span class="hljs-number">1</span>)<br><br>        <span class="hljs-variable language_">self</span>.data_dict = np.load(vgg16_npy_path, encoding=<span class="hljs-string">'latin1'</span>).item()<br>        <span class="hljs-variable language_">self</span>.wd = <span class="hljs-number">5e-4</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">"npy file loaded"</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">build</span>(<span class="hljs-params">self, rgb, train=<span class="hljs-literal">False</span>, num_classes=<span class="hljs-number">20</span>, random_init_fc8=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">              debug=<span class="hljs-literal">False</span>, use_dilated=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-string">"""</span><br><span class="hljs-string">        Build the VGG model using loaded weights</span><br><span class="hljs-string">        Parameters</span><br><span class="hljs-string">        ----------</span><br><span class="hljs-string">        rgb: image batch tensor</span><br><span class="hljs-string">            Image in rgb shap. Scaled to Intervall [0, 255]</span><br><span class="hljs-string">        train: bool</span><br><span class="hljs-string">            Whether to build train or inference graph</span><br><span class="hljs-string">        num_classes: int</span><br><span class="hljs-string">            How many classes should be predicted (by fc8)</span><br><span class="hljs-string">        random_init_fc8 : bool</span><br><span class="hljs-string">            Whether to initialize fc8 layer randomly.</span><br><span class="hljs-string">            Finetuning is required in this case.</span><br><span class="hljs-string">        debug: bool</span><br><span class="hljs-string">            Whether to print additional Debug Information.</span><br><span class="hljs-string">        """</span><br>        <span class="hljs-comment"># Convert RGB to BGR</span><br><br>        <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'Processing'</span>):<br><br>            red, green, blue = tf.split(rgb, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>            <span class="hljs-comment"># assert red.get_shape().as_list()[1:] == [224, 224, 1]</span><br>            <span class="hljs-comment"># assert green.get_shape().as_list()[1:] == [224, 224, 1]</span><br>            <span class="hljs-comment"># assert blue.get_shape().as_list()[1:] == [224, 224, 1]</span><br>            bgr = tf.concat([<br>                blue - VGG_MEAN[<span class="hljs-number">0</span>],<br>                green - VGG_MEAN[<span class="hljs-number">1</span>],<br>                red - VGG_MEAN[<span class="hljs-number">2</span>],<br>            ], <span class="hljs-number">3</span>)<br><br>            <span class="hljs-keyword">if</span> debug:<br>                bgr = tf.Print(bgr, [tf.shape(bgr)],<br>                               message=<span class="hljs-string">'Shape of input image: '</span>,<br>                               summarize=<span class="hljs-number">4</span>, first_n=<span class="hljs-number">1</span>)<br><br>        <span class="hljs-variable language_">self</span>.conv1_1 = <span class="hljs-variable language_">self</span>._conv_layer(bgr, <span class="hljs-string">"conv1_1"</span>)<br>        <span class="hljs-variable language_">self</span>.conv1_2 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.conv1_1, <span class="hljs-string">"conv1_2"</span>)<br>        <span class="hljs-variable language_">self</span>.pool1 = <span class="hljs-variable language_">self</span>._max_pool(<span class="hljs-variable language_">self</span>.conv1_2, <span class="hljs-string">'pool1'</span>, debug)<br><br>        <span class="hljs-variable language_">self</span>.conv2_1 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.pool1, <span class="hljs-string">"conv2_1"</span>)<br>        <span class="hljs-variable language_">self</span>.conv2_2 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.conv2_1, <span class="hljs-string">"conv2_2"</span>)<br>        <span class="hljs-variable language_">self</span>.pool2 = <span class="hljs-variable language_">self</span>._max_pool(<span class="hljs-variable language_">self</span>.conv2_2, <span class="hljs-string">'pool2'</span>, debug)<br><br>        <span class="hljs-variable language_">self</span>.conv3_1 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.pool2, <span class="hljs-string">"conv3_1"</span>)<br>        <span class="hljs-variable language_">self</span>.conv3_2 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.conv3_1, <span class="hljs-string">"conv3_2"</span>)<br>        <span class="hljs-variable language_">self</span>.conv3_3 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.conv3_2, <span class="hljs-string">"conv3_3"</span>)<br>        <span class="hljs-variable language_">self</span>.pool3 = <span class="hljs-variable language_">self</span>._max_pool(<span class="hljs-variable language_">self</span>.conv3_3, <span class="hljs-string">'pool3'</span>, debug)<br><br>        <span class="hljs-variable language_">self</span>.conv4_1 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.pool3, <span class="hljs-string">"conv4_1"</span>)<br>        <span class="hljs-variable language_">self</span>.conv4_2 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.conv4_1, <span class="hljs-string">"conv4_2"</span>)<br>        <span class="hljs-variable language_">self</span>.conv4_3 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.conv4_2, <span class="hljs-string">"conv4_3"</span>)<br><br>        <span class="hljs-keyword">if</span> use_dilated:<br>            pad = [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]<br>            <span class="hljs-variable language_">self</span>.pool4 = tf.nn.max_pool(<span class="hljs-variable language_">self</span>.conv4_3, ksize=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],<br>                                        strides=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>                                        padding=<span class="hljs-string">'SAME'</span>, name=<span class="hljs-string">'pool4'</span>)<br>            <span class="hljs-variable language_">self</span>.pool4 = tf.space_to_batch(<span class="hljs-variable language_">self</span>.pool4,<br>                                           paddings=pad, block_size=<span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.pool4 = <span class="hljs-variable language_">self</span>._max_pool(<span class="hljs-variable language_">self</span>.conv4_3, <span class="hljs-string">'pool4'</span>, debug)<br><br>        <span class="hljs-variable language_">self</span>.conv5_1 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.pool4, <span class="hljs-string">"conv5_1"</span>)<br>        <span class="hljs-variable language_">self</span>.conv5_2 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.conv5_1, <span class="hljs-string">"conv5_2"</span>)<br>        <span class="hljs-variable language_">self</span>.conv5_3 = <span class="hljs-variable language_">self</span>._conv_layer(<span class="hljs-variable language_">self</span>.conv5_2, <span class="hljs-string">"conv5_3"</span>)<br>        <span class="hljs-keyword">if</span> use_dilated:<br>            pad = [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]<br>            <span class="hljs-variable language_">self</span>.pool5 = tf.nn.max_pool(<span class="hljs-variable language_">self</span>.conv5_3, ksize=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],<br>                                        strides=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>                                        padding=<span class="hljs-string">'SAME'</span>, name=<span class="hljs-string">'pool5'</span>)<br>            <span class="hljs-variable language_">self</span>.pool5 = tf.space_to_batch(<span class="hljs-variable language_">self</span>.pool5,<br>                                           paddings=pad, block_size=<span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.pool5 = <span class="hljs-variable language_">self</span>._max_pool(<span class="hljs-variable language_">self</span>.conv5_3, <span class="hljs-string">'pool5'</span>, debug)<br><br>        <span class="hljs-variable language_">self</span>.fc6 = <span class="hljs-variable language_">self</span>._fc_layer(<span class="hljs-variable language_">self</span>.pool5, <span class="hljs-string">"fc6"</span>)<br><br>        <span class="hljs-keyword">if</span> train:<br>            <span class="hljs-variable language_">self</span>.fc6 = tf.nn.dropout(<span class="hljs-variable language_">self</span>.fc6, <span class="hljs-number">0.5</span>)<br><br>        <span class="hljs-variable language_">self</span>.fc7 = <span class="hljs-variable language_">self</span>._fc_layer(<span class="hljs-variable language_">self</span>.fc6, <span class="hljs-string">"fc7"</span>)<br>        <span class="hljs-keyword">if</span> train:<br>            <span class="hljs-variable language_">self</span>.fc7 = tf.nn.dropout(<span class="hljs-variable language_">self</span>.fc7, <span class="hljs-number">0.5</span>)<br><br>        <span class="hljs-keyword">if</span> use_dilated:<br>            <span class="hljs-variable language_">self</span>.pool5 = tf.batch_to_space(<span class="hljs-variable language_">self</span>.pool5, crops=pad, block_size=<span class="hljs-number">2</span>)<br>            <span class="hljs-variable language_">self</span>.pool5 = tf.batch_to_space(<span class="hljs-variable language_">self</span>.pool5, crops=pad, block_size=<span class="hljs-number">2</span>)<br>            <span class="hljs-variable language_">self</span>.fc7 = tf.batch_to_space(<span class="hljs-variable language_">self</span>.fc7, crops=pad, block_size=<span class="hljs-number">2</span>)<br>            <span class="hljs-variable language_">self</span>.fc7 = tf.batch_to_space(<span class="hljs-variable language_">self</span>.fc7, crops=pad, block_size=<span class="hljs-number">2</span>)<br>            <span class="hljs-keyword">return</span><br><br>        <span class="hljs-keyword">if</span> random_init_fc8:<br>            <span class="hljs-variable language_">self</span>.score_fr = <span class="hljs-variable language_">self</span>._score_layer(<span class="hljs-variable language_">self</span>.fc7, <span class="hljs-string">"score_fr"</span>,<br>                                              num_classes)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.score_fr = <span class="hljs-variable language_">self</span>._fc_layer(<span class="hljs-variable language_">self</span>.fc7, <span class="hljs-string">"score_fr"</span>,<br>                                           num_classes=num_classes,<br>                                           relu=<span class="hljs-literal">False</span>)<br><br>        <span class="hljs-variable language_">self</span>.pred = tf.argmax(<span class="hljs-variable language_">self</span>.score_fr, dimension=<span class="hljs-number">3</span>)<br><br>        <span class="hljs-variable language_">self</span>.upscore2 = <span class="hljs-variable language_">self</span>._upscore_layer(<span class="hljs-variable language_">self</span>.score_fr,<br>                                            shape=tf.shape(<span class="hljs-variable language_">self</span>.pool4),<br>                                            num_classes=num_classes,<br>                                            debug=debug, name=<span class="hljs-string">'upscore2'</span>,<br>                                            ksize=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.score_pool4 = <span class="hljs-variable language_">self</span>._score_layer(<span class="hljs-variable language_">self</span>.pool4, <span class="hljs-string">"score_pool4"</span>,<br>                                             num_classes=num_classes)<br>        <span class="hljs-variable language_">self</span>.fuse_pool4 = tf.add(<span class="hljs-variable language_">self</span>.upscore2, <span class="hljs-variable language_">self</span>.score_pool4)<br><br>        <span class="hljs-variable language_">self</span>.upscore4 = <span class="hljs-variable language_">self</span>._upscore_layer(<span class="hljs-variable language_">self</span>.fuse_pool4,<br>                                            shape=tf.shape(<span class="hljs-variable language_">self</span>.pool3),<br>                                            num_classes=num_classes,<br>                                            debug=debug, name=<span class="hljs-string">'upscore4'</span>,<br>                                            ksize=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.score_pool3 = <span class="hljs-variable language_">self</span>._score_layer(<span class="hljs-variable language_">self</span>.pool3, <span class="hljs-string">"score_pool3"</span>,<br>                                             num_classes=num_classes)<br>        <span class="hljs-variable language_">self</span>.fuse_pool3 = tf.add(<span class="hljs-variable language_">self</span>.upscore4, <span class="hljs-variable language_">self</span>.score_pool3)<br><br>        <span class="hljs-variable language_">self</span>.upscore32 = <span class="hljs-variable language_">self</span>._upscore_layer(<span class="hljs-variable language_">self</span>.fuse_pool3,<br>                                             shape=tf.shape(bgr),<br>                                             num_classes=num_classes,<br>                                             debug=debug, name=<span class="hljs-string">'upscore32'</span>,<br>                                             ksize=<span class="hljs-number">16</span>, stride=<span class="hljs-number">8</span>)<br><br>        <span class="hljs-variable language_">self</span>.pred_up = tf.argmax(<span class="hljs-variable language_">self</span>.upscore32, dimension=<span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_max_pool</span>(<span class="hljs-params">self, bottom, name, debug</span>):<br>        pool = tf.nn.max_pool(bottom, ksize=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], strides=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],<br>                              padding=<span class="hljs-string">'SAME'</span>, name=name)<br><br>        <span class="hljs-keyword">if</span> debug:<br>            pool = tf.Print(pool, [tf.shape(pool)],<br>                            message=<span class="hljs-string">'Shape of %s'</span> % name,<br>                            summarize=<span class="hljs-number">4</span>, first_n=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> pool<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_conv_layer</span>(<span class="hljs-params">self, bottom, name</span>):<br>        <span class="hljs-keyword">with</span> tf.variable_scope(name) <span class="hljs-keyword">as</span> scope:<br>            filt = <span class="hljs-variable language_">self</span>.get_conv_filter(name)<br>            conv = tf.nn.conv2d(bottom, filt, [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'SAME'</span>)<br><br>            conv_biases = <span class="hljs-variable language_">self</span>.get_bias(name)<br>            bias = tf.nn.bias_add(conv, conv_biases)<br><br>            relu = tf.nn.relu(bias)<br>            <span class="hljs-comment"># Add summary to Tensorboard</span><br>            _activation_summary(relu)<br>            <span class="hljs-keyword">return</span> relu<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_fc_layer</span>(<span class="hljs-params">self, bottom, name, num_classes=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                  relu=<span class="hljs-literal">True</span>, debug=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-keyword">with</span> tf.variable_scope(name) <span class="hljs-keyword">as</span> scope:<br>            shape = bottom.get_shape().as_list()<br><br>            <span class="hljs-keyword">if</span> name == <span class="hljs-string">'fc6'</span>:<br>                filt = <span class="hljs-variable language_">self</span>.get_fc_weight_reshape(name, [<span class="hljs-number">7</span>, <span class="hljs-number">7</span>, <span class="hljs-number">512</span>, <span class="hljs-number">4096</span>])<br>            <span class="hljs-keyword">elif</span> name == <span class="hljs-string">'score_fr'</span>:<br>                name = <span class="hljs-string">'fc8'</span>  <span class="hljs-comment"># Name of score_fr layer in VGG Model</span><br>                filt = <span class="hljs-variable language_">self</span>.get_fc_weight_reshape(name, [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4096</span>, <span class="hljs-number">1000</span>],<br>                                                  num_classes=num_classes)<br>            <span class="hljs-keyword">else</span>:<br>                filt = <span class="hljs-variable language_">self</span>.get_fc_weight_reshape(name, [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>])<br><br>            <span class="hljs-variable language_">self</span>._add_wd_and_summary(filt, <span class="hljs-variable language_">self</span>.wd, <span class="hljs-string">"fc_wlosses"</span>)<br><br>            conv = tf.nn.conv2d(bottom, filt, [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'SAME'</span>)<br>            conv_biases = <span class="hljs-variable language_">self</span>.get_bias(name, num_classes=num_classes)<br>            bias = tf.nn.bias_add(conv, conv_biases)<br><br>            <span class="hljs-keyword">if</span> relu:<br>                bias = tf.nn.relu(bias)<br>            _activation_summary(bias)<br><br>            <span class="hljs-keyword">if</span> debug:<br>                bias = tf.Print(bias, [tf.shape(bias)],<br>                                message=<span class="hljs-string">'Shape of %s'</span> % name,<br>                                summarize=<span class="hljs-number">4</span>, first_n=<span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">return</span> bias<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_score_layer</span>(<span class="hljs-params">self, bottom, name, num_classes</span>):<br>        <span class="hljs-keyword">with</span> tf.variable_scope(name) <span class="hljs-keyword">as</span> scope:<br>            <span class="hljs-comment"># get number of input channels</span><br>            in_features = bottom.get_shape()[<span class="hljs-number">3</span>].value<br>            shape = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, in_features, num_classes]<br>            <span class="hljs-comment"># He initialization Sheme</span><br>            <span class="hljs-keyword">if</span> name == <span class="hljs-string">"score_fr"</span>:<br>                num_input = in_features<br>                stddev = (<span class="hljs-number">2</span> / num_input)**<span class="hljs-number">0.5</span><br>            <span class="hljs-keyword">elif</span> name == <span class="hljs-string">"score_pool4"</span>:<br>                stddev = <span class="hljs-number">0.001</span><br>            <span class="hljs-keyword">elif</span> name == <span class="hljs-string">"score_pool3"</span>:<br>                stddev = <span class="hljs-number">0.0001</span><br>            <span class="hljs-comment"># Apply convolution</span><br>            w_decay = <span class="hljs-variable language_">self</span>.wd<br><br>            weights = <span class="hljs-variable language_">self</span>._variable_with_weight_decay(shape, stddev, w_decay,<br>                                                       decoder=<span class="hljs-literal">True</span>)<br>            conv = tf.nn.conv2d(bottom, weights, [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'SAME'</span>)<br>            <span class="hljs-comment"># Apply bias</span><br>            conv_biases = <span class="hljs-variable language_">self</span>._bias_variable([num_classes], constant=<span class="hljs-number">0.0</span>)<br>            bias = tf.nn.bias_add(conv, conv_biases)<br><br>            _activation_summary(bias)<br><br>            <span class="hljs-keyword">return</span> bias<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_upscore_layer</span>(<span class="hljs-params">self, bottom, shape,</span><br><span class="hljs-params">                       num_classes, name, debug,</span><br><span class="hljs-params">                       ksize=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span></span>):<br>        strides = [<span class="hljs-number">1</span>, stride, stride, <span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">with</span> tf.variable_scope(name):<br>            in_features = bottom.get_shape()[<span class="hljs-number">3</span>].value<br><br>            <span class="hljs-keyword">if</span> shape <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                <span class="hljs-comment"># Compute shape out of Bottom</span><br>                in_shape = tf.shape(bottom)<br><br>                h = ((in_shape[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>) * stride) + <span class="hljs-number">1</span><br>                w = ((in_shape[<span class="hljs-number">2</span>] - <span class="hljs-number">1</span>) * stride) + <span class="hljs-number">1</span><br>                new_shape = [in_shape[<span class="hljs-number">0</span>], h, w, num_classes]<br>            <span class="hljs-keyword">else</span>:<br>                new_shape = [shape[<span class="hljs-number">0</span>], shape[<span class="hljs-number">1</span>], shape[<span class="hljs-number">2</span>], num_classes]<br>            output_shape = tf.stack(new_shape)<br><br>            logging.debug(<span class="hljs-string">"Layer: %s, Fan-in: %d"</span> % (name, in_features))<br>            f_shape = [ksize, ksize, num_classes, in_features]<br><br>            <span class="hljs-comment"># create</span><br>            num_input = ksize * ksize * in_features / stride<br>            stddev = (<span class="hljs-number">2</span> / num_input)**<span class="hljs-number">0.5</span><br><br>            weights = <span class="hljs-variable language_">self</span>.get_deconv_filter(f_shape)<br>            <span class="hljs-variable language_">self</span>._add_wd_and_summary(weights, <span class="hljs-variable language_">self</span>.wd, <span class="hljs-string">"fc_wlosses"</span>)<br>            deconv = tf.nn.conv2d_transpose(bottom, weights, output_shape,<br>                                            strides=strides, padding=<span class="hljs-string">'SAME'</span>)<br><br>            <span class="hljs-keyword">if</span> debug:<br>                deconv = tf.Print(deconv, [tf.shape(deconv)],<br>                                  message=<span class="hljs-string">'Shape of %s'</span> % name,<br>                                  summarize=<span class="hljs-number">4</span>, first_n=<span class="hljs-number">1</span>)<br><br>        _activation_summary(deconv)<br>        <span class="hljs-keyword">return</span> deconv<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_deconv_filter</span>(<span class="hljs-params">self, f_shape</span>):<br>        width = f_shape[<span class="hljs-number">0</span>]<br>        height = f_shape[<span class="hljs-number">1</span>]<br>        f = ceil(width/<span class="hljs-number">2.0</span>)<br>        c = (<span class="hljs-number">2</span> * f - <span class="hljs-number">1</span> - f % <span class="hljs-number">2</span>) / (<span class="hljs-number">2.0</span> * f)<br>        bilinear = np.zeros([f_shape[<span class="hljs-number">0</span>], f_shape[<span class="hljs-number">1</span>]])<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(width):<br>            <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(height):<br>                value = (<span class="hljs-number">1</span> - <span class="hljs-built_in">abs</span>(x / f - c)) * (<span class="hljs-number">1</span> - <span class="hljs-built_in">abs</span>(y / f - c))<br>                bilinear[x, y] = value<br>        weights = np.zeros(f_shape)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(f_shape[<span class="hljs-number">2</span>]):<br>            weights[:, :, i, i] = bilinear<br><br>        init = tf.constant_initializer(value=weights,<br>                                       dtype=tf.float32)<br>        var = tf.get_variable(name=<span class="hljs-string">"up_filter"</span>, initializer=init,<br>                              shape=weights.shape)<br>        <span class="hljs-keyword">return</span> var<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_conv_filter</span>(<span class="hljs-params">self, name</span>):<br>        init = tf.constant_initializer(value=<span class="hljs-variable language_">self</span>.data_dict[name][<span class="hljs-number">0</span>],<br>                                       dtype=tf.float32)<br>        shape = <span class="hljs-variable language_">self</span>.data_dict[name][<span class="hljs-number">0</span>].shape<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">'Layer name: %s'</span> % name)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">'Layer shape: %s'</span> % <span class="hljs-built_in">str</span>(shape))<br>        var = tf.get_variable(name=<span class="hljs-string">"filter"</span>, initializer=init, shape=shape)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> tf.get_variable_scope().reuse:<br>            weight_decay = tf.multiply(tf.nn.l2_loss(var), <span class="hljs-variable language_">self</span>.wd,<br>                                       name=<span class="hljs-string">'weight_loss'</span>)<br>            tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES,<br>                                 weight_decay)<br>        _variable_summaries(var)<br>        <span class="hljs-keyword">return</span> var<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_bias</span>(<span class="hljs-params">self, name, num_classes=<span class="hljs-literal">None</span></span>):<br>        bias_wights = <span class="hljs-variable language_">self</span>.data_dict[name][<span class="hljs-number">1</span>]<br>        shape = <span class="hljs-variable language_">self</span>.data_dict[name][<span class="hljs-number">1</span>].shape<br>        <span class="hljs-keyword">if</span> name == <span class="hljs-string">'fc8'</span>:<br>            bias_wights = <span class="hljs-variable language_">self</span>._bias_reshape(bias_wights, shape[<span class="hljs-number">0</span>],<br>                                             num_classes)<br>            shape = [num_classes]<br>        init = tf.constant_initializer(value=bias_wights,<br>                                       dtype=tf.float32)<br>        var = tf.get_variable(name=<span class="hljs-string">"biases"</span>, initializer=init, shape=shape)<br>        _variable_summaries(var)<br>        <span class="hljs-keyword">return</span> var<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_fc_weight</span>(<span class="hljs-params">self, name</span>):<br>        init = tf.constant_initializer(value=<span class="hljs-variable language_">self</span>.data_dict[name][<span class="hljs-number">0</span>],<br>                                       dtype=tf.float32)<br>        shape = <span class="hljs-variable language_">self</span>.data_dict[name][<span class="hljs-number">0</span>].shape<br>        var = tf.get_variable(name=<span class="hljs-string">"weights"</span>, initializer=init, shape=shape)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> tf.get_variable_scope().reuse:<br>            weight_decay = tf.multiply(tf.nn.l2_loss(var), <span class="hljs-variable language_">self</span>.wd,<br>                                       name=<span class="hljs-string">'weight_loss'</span>)<br>            tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES,<br>                                 weight_decay)<br>        _variable_summaries(var)<br>        <span class="hljs-keyword">return</span> var<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_bias_reshape</span>(<span class="hljs-params">self, bweight, num_orig, num_new</span>):<br>        <span class="hljs-string">""" Build bias weights for filter produces with `_summary_reshape`</span><br><span class="hljs-string"></span><br><span class="hljs-string">        """</span><br>        n_averaged_elements = num_orig//num_new<br>        avg_bweight = np.zeros(num_new)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_orig, n_averaged_elements):<br>            start_idx = i<br>            end_idx = start_idx + n_averaged_elements<br>            avg_idx = start_idx//n_averaged_elements<br>            <span class="hljs-keyword">if</span> avg_idx == num_new:<br>                <span class="hljs-keyword">break</span><br>            avg_bweight[avg_idx] = np.mean(bweight[start_idx:end_idx])<br>        <span class="hljs-keyword">return</span> avg_bweight<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_summary_reshape</span>(<span class="hljs-params">self, fweight, shape, num_new</span>):<br>        <span class="hljs-string">""" Produce weights for a reduced fully-connected layer.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        FC8 of VGG produces 1000 classes. Most semantic segmentation</span><br><span class="hljs-string">        task require much less classes. This reshapes the original weights</span><br><span class="hljs-string">        to be used in a fully-convolutional layer which produces num_new</span><br><span class="hljs-string">        classes. To archive this the average (mean) of n adjanced classes is</span><br><span class="hljs-string">        taken.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Consider reordering fweight, to perserve semantic meaning of the</span><br><span class="hljs-string">        weights.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">          fweight: original weights</span><br><span class="hljs-string">          shape: shape of the desired fully-convolutional layer</span><br><span class="hljs-string">          num_new: number of new classes</span><br><span class="hljs-string"></span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">          Filter weights for `num_new` classes.</span><br><span class="hljs-string">        """</span><br>        num_orig = shape[<span class="hljs-number">3</span>]<br>        shape[<span class="hljs-number">3</span>] = num_new<br>        <span class="hljs-keyword">assert</span>(num_new &lt; num_orig)<br>        n_averaged_elements = num_orig//num_new<br>        avg_fweight = np.zeros(shape)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_orig, n_averaged_elements):<br>            start_idx = i<br>            end_idx = start_idx + n_averaged_elements<br>            avg_idx = start_idx//n_averaged_elements<br>            <span class="hljs-keyword">if</span> avg_idx == num_new:<br>                <span class="hljs-keyword">break</span><br>            avg_fweight[:, :, :, avg_idx] = np.mean(<br>                fweight[:, :, :, start_idx:end_idx], axis=<span class="hljs-number">3</span>)<br>        <span class="hljs-keyword">return</span> avg_fweight<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_variable_with_weight_decay</span>(<span class="hljs-params">self, shape, stddev, wd, decoder=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-string">"""Helper to create an initialized Variable with weight decay.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Note that the Variable is initialized with a truncated normal</span><br><span class="hljs-string">        distribution.</span><br><span class="hljs-string">        A weight decay is added only if one is specified.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">          name: name of the variable</span><br><span class="hljs-string">          shape: list of ints</span><br><span class="hljs-string">          stddev: standard deviation of a truncated Gaussian</span><br><span class="hljs-string">          wd: add L2Loss weight decay multiplied by this float. If None, weight</span><br><span class="hljs-string">              decay is not added for this Variable.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">          Variable Tensor</span><br><span class="hljs-string">        """</span><br><br>        initializer = tf.truncated_normal_initializer(stddev=stddev)<br>        var = tf.get_variable(<span class="hljs-string">'weights'</span>, shape=shape,<br>                              initializer=initializer)<br><br>        collection_name = tf.GraphKeys.REGULARIZATION_LOSSES<br>        <span class="hljs-keyword">if</span> wd <span class="hljs-keyword">and</span> (<span class="hljs-keyword">not</span> tf.get_variable_scope().reuse):<br>            weight_decay = tf.multiply(<br>                tf.nn.l2_loss(var), wd, name=<span class="hljs-string">'weight_loss'</span>)<br>            tf.add_to_collection(collection_name, weight_decay)<br>        _variable_summaries(var)<br>        <span class="hljs-keyword">return</span> var<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_add_wd_and_summary</span>(<span class="hljs-params">self, var, wd, collection_name=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-keyword">if</span> collection_name <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            collection_name = tf.GraphKeys.REGULARIZATION_LOSSES<br>        <span class="hljs-keyword">if</span> wd <span class="hljs-keyword">and</span> (<span class="hljs-keyword">not</span> tf.get_variable_scope().reuse):<br>            weight_decay = tf.multiply(<br>                tf.nn.l2_loss(var), wd, name=<span class="hljs-string">'weight_loss'</span>)<br>            tf.add_to_collection(collection_name, weight_decay)<br>        _variable_summaries(var)<br>        <span class="hljs-keyword">return</span> var<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_bias_variable</span>(<span class="hljs-params">self, shape, constant=<span class="hljs-number">0.0</span></span>):<br>        initializer = tf.constant_initializer(constant)<br>        var = tf.get_variable(name=<span class="hljs-string">'biases'</span>, shape=shape,<br>                              initializer=initializer)<br>        _variable_summaries(var)<br>        <span class="hljs-keyword">return</span> var<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_fc_weight_reshape</span>(<span class="hljs-params">self, name, shape, num_classes=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">'Layer name: %s'</span> % name)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">'Layer shape: %s'</span> % shape)<br>        weights = <span class="hljs-variable language_">self</span>.data_dict[name][<span class="hljs-number">0</span>]<br>        weights = weights.reshape(shape)<br>        <span class="hljs-keyword">if</span> num_classes <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            weights = <span class="hljs-variable language_">self</span>._summary_reshape(weights, shape,<br>                                            num_new=num_classes)<br>        init = tf.constant_initializer(value=weights,<br>                                       dtype=tf.float32)<br>        var = tf.get_variable(name=<span class="hljs-string">"weights"</span>, initializer=init, shape=shape)<br>        <span class="hljs-keyword">return</span> var<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_activation_summary</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-string">"""Helper to create summaries for activations.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Creates a summary that provides a histogram of activations.</span><br><span class="hljs-string">    Creates a summary that measure the sparsity of activations.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">      x: Tensor</span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">      nothing</span><br><span class="hljs-string">    """</span><br>    <span class="hljs-comment"># Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training</span><br>    <span class="hljs-comment"># session. This helps the clarity of presentation on tensorboard.</span><br>    tensor_name = x.op.name<br>    <span class="hljs-comment"># tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)</span><br>    tf.summary.histogram(tensor_name + <span class="hljs-string">'/activations'</span>, x)<br>    tf.summary.scalar(tensor_name + <span class="hljs-string">'/sparsity'</span>, tf.nn.zero_fraction(x))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_variable_summaries</span>(<span class="hljs-params">var</span>):<br>    <span class="hljs-string">"""Attach a lot of summaries to a Tensor."""</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> tf.get_variable_scope().reuse:<br>        name = var.op.name<br>        logging.info(<span class="hljs-string">"Creating Summary for: %s"</span> % name)<br>        <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'summaries'</span>):<br>            mean = tf.reduce_mean(var)<br>            tf.summary.scalar(name + <span class="hljs-string">'/mean'</span>, mean)<br>            <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">'stddev'</span>):<br>                stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))<br>            tf.summary.scalar(name + <span class="hljs-string">'/sttdev'</span>, stddev)<br>            tf.summary.scalar(name + <span class="hljs-string">'/max'</span>, tf.reduce_max(var))<br>            tf.summary.scalar(name + <span class="hljs-string">'/min'</span>, tf.reduce_min(var))<br>            tf.summary.histogram(name, var)<br></code></pre></td></tr></table></figure>

<h5 id="fcn-调包"><a href="#fcn-调包" class="headerlink" title="fcn 调包"></a>fcn 调包</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> abc <span class="hljs-keyword">import</span> ABCMeta<br><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_maybe_pad</span>(<span class="hljs-params">x, size</span>):<br>    hpad = size[<span class="hljs-number">0</span>] - x.shape[<span class="hljs-number">2</span>]<br>    wpad = size[<span class="hljs-number">1</span>] - x.shape[<span class="hljs-number">3</span>]<br>    <span class="hljs-keyword">if</span> hpad + wpad &gt; <span class="hljs-number">0</span>:<br>        x = F.pad(x, (<span class="hljs-number">0</span>, wpad, <span class="hljs-number">0</span>, hpad, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span> ))<br>    <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">VGGFCN</span>(nn.Module, metaclass=ABCMeta):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, n_classes</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">assert</span> in_channels == <span class="hljs-number">3</span><br>        <span class="hljs-variable language_">self</span>.n_classes = n_classes<br>        <span class="hljs-variable language_">self</span>.vgg16 = models.vgg16(pretrained=<span class="hljs-literal">True</span>)<br>        <span class="hljs-variable language_">self</span>.classifier = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">4096</span>, kernel_size=<span class="hljs-number">7</span>, padding=<span class="hljs-number">3</span>),<br>            nn.ReLU(<span class="hljs-literal">True</span>),<br>            nn.Dropout(),<br>            nn.Conv2d(<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>, kernel_size=<span class="hljs-number">1</span>),<br>            nn.ReLU(<span class="hljs-literal">True</span>),<br>            nn.Dropout(),<br>            nn.Conv2d(<span class="hljs-number">4096</span>, n_classes, kernel_size=<span class="hljs-number">1</span>),<br>        )<br><br>        <span class="hljs-variable language_">self</span>._initialize_weights()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_initialize_weights</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-variable language_">self</span>.classifier[<span class="hljs-number">0</span>].weight.data = (<br>            <span class="hljs-variable language_">self</span>.vgg16.classifier[<span class="hljs-number">0</span>].weight.data.view(<br>                <span class="hljs-variable language_">self</span>.classifier[<span class="hljs-number">0</span>].weight.size())<br>        )<br>        <span class="hljs-variable language_">self</span>.classifier[<span class="hljs-number">3</span>].weight.data = (<br>            <span class="hljs-variable language_">self</span>.vgg16.classifier[<span class="hljs-number">3</span>].weight.data.view(<br>                <span class="hljs-variable language_">self</span>.classifier[<span class="hljs-number">3</span>].weight.size())<br>        )<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">VGGFCN32</span>(<span class="hljs-title class_ inherited__">VGGFCN</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        input_height, input_width = x.shape[<span class="hljs-number">2</span>], x.shape[<span class="hljs-number">3</span>]<br>        x = <span class="hljs-variable language_">self</span>.vgg16.features(x)<br>        x = <span class="hljs-variable language_">self</span>.classifier(x)<br>        x = F.interpolate(x, size=(input_height, input_width),<br>                          mode=<span class="hljs-string">'bilinear'</span>, align_corners=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">VGGFCN16</span>(<span class="hljs-title class_ inherited__">VGGFCN</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, n_classes</span>):<br>        <span class="hljs-built_in">super</span>().__init__(in_channels, n_classes)<br>        <span class="hljs-variable language_">self</span>.score4 = nn.Conv2d(<span class="hljs-number">512</span>, n_classes, kernel_size=<span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>.upscale5 = nn.ConvTranspose2d(<br>            n_classes, n_classes, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        input_height, input_width = x.shape[<span class="hljs-number">2</span>], x.shape[<span class="hljs-number">3</span>]<br>        pool4 = <span class="hljs-variable language_">self</span>.vgg16.features[:-<span class="hljs-number">7</span>](x)<br>        pool5 = <span class="hljs-variable language_">self</span>.vgg16.features[-<span class="hljs-number">7</span>:](pool4)<br>        pool5_upscaled = <span class="hljs-variable language_">self</span>.upscale5(<span class="hljs-variable language_">self</span>.classifier(pool5))<br>        pool4 = <span class="hljs-variable language_">self</span>.score4(pool4)<br>        x = pool4 + pool5_upscaled<br>        x = F.interpolate(x, size=(input_height, input_width),<br>                          mode=<span class="hljs-string">'bilinear'</span>, align_corners=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">VGGFCN8</span>(<span class="hljs-title class_ inherited__">VGGFCN</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, n_classes</span>):<br>        <span class="hljs-built_in">super</span>().__init__(in_channels, n_classes)<br>        <span class="hljs-variable language_">self</span>.upscale4 = nn.ConvTranspose2d(<br>            n_classes, n_classes, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.score4 = nn.Conv2d(<br>            <span class="hljs-number">512</span>, n_classes, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>.score3 = nn.Conv2d(<br>            <span class="hljs-number">256</span>, n_classes, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>.upscale5 = nn.ConvTranspose2d(<br>            n_classes, n_classes, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        input_height, input_width = x.shape[<span class="hljs-number">2</span>], x.shape[<span class="hljs-number">3</span>]<br>        pool3 = <span class="hljs-variable language_">self</span>.vgg16.features[:-<span class="hljs-number">14</span>](x)<br>        pool4 = <span class="hljs-variable language_">self</span>.vgg16.features[-<span class="hljs-number">14</span>:-<span class="hljs-number">7</span>](pool3)<br>        pool5 = <span class="hljs-variable language_">self</span>.vgg16.features[-<span class="hljs-number">7</span>:](pool4)<br>        pool5_upscaled = <span class="hljs-variable language_">self</span>.upscale5(<span class="hljs-variable language_">self</span>.classifier(pool5))<br>        pool5_upscaled = _maybe_pad(pool5_upscaled, pool4.shape[<span class="hljs-number">2</span>:])<br>        pool4_scores = <span class="hljs-variable language_">self</span>.score4(pool4)<br>        pool4_fused = pool4_scores + pool5_upscaled<br>        pool4_upscaled = <span class="hljs-variable language_">self</span>.upscale4(pool4_fused)<br>        pool4_upscaled = _maybe_pad(pool4_upscaled, pool3.shape[<span class="hljs-number">2</span>:])<br>        x = <span class="hljs-variable language_">self</span>.score3(pool3) + pool4_upscaled<br>        x = F.interpolate(x, size=(input_height, input_width),<br>                          mode=<span class="hljs-string">'bilinear'</span>, align_corners=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure>

<h4 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h4><h3 id="U-Net"><a href="#U-Net" class="headerlink" title="U-Net"></a><strong>U-Net</strong></h3><ul>
<li><strong>优点</strong>：简单易用，适用于小数据集，尤其在医学图像分割中表现良好。</li>
<li><strong>缺点</strong>：容易过拟合，不太适合大规模数据集。</li>
</ul>
<p><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/1740236677445SwkUbDFUtolVEKxc4dmcbrOknJf.png" alt="1740236677445SwkUbDFUtolVEKxc4dmcbrOknJf.png"></p>
<h4 id="提出初衷-1"><a href="#提出初衷-1" class="headerlink" title="提出初衷"></a>提出初衷</h4><p>U-Net 是一种经典且广泛使用的分割模型，以其简单、高效、易于理解和构建的特点而受到青睐，尤其适合从小数据集中进行训练。该模型最早于 2015 年在论文《U-Net: Convolutional Networks for Biomedical Image Segmentation》中被提出，至今仍然是医学图像分割领域的重要基础模型。</p>
<p><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/1740236700448YM2HbihrkonVkixR0KdcPLcBnLc.png" alt="1740236700448YM2HbihrkonVkixR0KdcPLcBnLc.png"></p>
<p><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/1740236696443Voorb6LuJopG3exmtulcaySynjc.png" alt="1740236696443Voorb6LuJopG3exmtulcaySynjc.png"></p>
<p><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/1740236682500NfPrbS5SNoEjsFxFFptcl471nhb.png" alt="1740236682500NfPrbS5SNoEjsFxFFptcl471nhb.png"></p>
<ol>
<li>Unet 提出的初衷是为了解决医学图像分割的问题；</li>
<li>一种 U 型的网络结构来获取上下文的信息和位置信息；</li>
<li>在 2015 年的 ISBI cell tracking 比赛中获得了多个第一，一开始这是为了解决细胞层面的分割的任务的</li>
</ol>
<h4 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/1740236655458N3Vab29uNorFHwxpINwc5s6unkh.png" alt="1740236655458N3Vab29uNorFHwxpINwc5s6unkh.png"></p>
<p>U-Net 网络是一种经典的编码器-解码器结构，因其整体结构形似大写的英文字母“U”而得名。它广泛应用于医学图像分割等领域。U-Net 的设计非常简洁：前半部分用于特征提取（编码器），后半部分用于上采样（解码器）。</p>
<h5 id="编码器（Encoder）"><a href="#编码器（Encoder）" class="headerlink" title="编码器（Encoder）"></a>编码器（Encoder）</h5><p>编码器位于网络的左半部分，主要由多个下采样模块组成。每个模块包含两个 3×3 的卷积层（激活函数为 ReLU），后接一个 2×2 的最大池化（Max Pooling）层，用于特征提取和空间尺寸的减半。通过这种结构，编码器能够逐步提取图像的深层特征，同时扩大感受野。</p>
<h5 id="解码器（Decoder）"><a href="#解码器（Decoder）" class="headerlink" title="解码器（Decoder）"></a>解码器（Decoder）</h5><p>解码器位于网络的右半部分，主要由上采样模块组成。每个模块包含一个 2×2 的反卷积层（上采样卷积层），用于将特征图的空间尺寸恢复到与编码器对应层相同的大小。随后，解码器通过特征拼接（concatenation）将上采样后的特征图与编码器中对应层的特征图进行通道级拼接，最后通过两个 3×3 的卷积层（激活函数为 ReLU）进一步融合特征。这种结构能够有效地结合深层特征和浅层特征，兼顾全局语义信息和局部细节。</p>
<h5 id="特征融合方式"><a href="#特征融合方式" class="headerlink" title="特征融合方式"></a>特征融合方式</h5><p>与 FCN 网络通过特征图对应像素值的相加来融合特征不同，U-Net 采用通道级拼接的方式。这种方式可以形成更厚的特征图，从而保留更多的细节信息，但也增加了显存的消耗。</p>
<h3 id="U-Net-的优点"><a href="#U-Net-的优点" class="headerlink" title="U-Net 的优点"></a>U-Net 的优点</h3><ol>
<li><strong>多尺度特征融合</strong>：U-Net 通过拼接深层和浅层特征图，能够充分利用不同层次的特征。浅层卷积关注纹理和细节特征，而深层网络关注更高级的语义特征。这种融合方式使得模型能够更好地处理复杂的分割任务。</li>
<li><strong>边缘特征的保留</strong>：在下采样过程中，虽然会损失一些边缘特征，但通过特征拼接，解码器能够从编码器的浅层特征中找回这些丢失的边缘信息，从而提高分割的精度。</li>
</ol>
<p>Unet 的好处我感觉是：网络层越深得到的特征图，有着更大的视野域，浅层卷积关注纹理特征，深层网络关注本质的那种特征，所以深层浅层特征都是有格子的意义的；另外一点是通过反卷积得到的更大的尺寸的特征图的边缘，是缺少信息的，毕竟每一次下采样提炼特征的同时，也必然会损失一些边缘特征，而失去的特征并不能从上采样中找回，因此通过特征的拼接，来实现边缘特征的一个找回。</p>
<p>下面是一些与医学相关的数据集以及对应的提取码,有兴趣的同学可以下载下来跑一下。</p>
<table>
<tr>
<td>**数据集名称**<br></td><td>**下载链接**<td>**提取码**<br></td></td></tr>
<tr>
<td>Cell dataset (dsb2018)<br></td><td>https://pan.baidu.com/share/init?surl=BaVrzYdrSP78CwYaRzZr1w<td>5l54<br></td></td></tr>
<tr>
<td>Liver dataset<br></td><td>https://pan.baidu.com/share/init?surl=FljGCVzu7HPYpwAKvSVN4Q<td>5l88<br></td></td></tr>
<tr>
<td>Cell dataset (isbi)<br></td><td>https://pan.baidu.com/share/init?surl=FkfnhU-RnYFZti62-f8AVA<td>14rz<br></td></td></tr>
<tr>
<td>Lung dataset<br></td><td>https://pan.baidu.com/share/init?surl=sLFRmtG2TOTEgUKniJf7AA<td>qdwo<br></td></td></tr>
<tr>
<td>Corneal Nerve dataset<br></td><td>https://pan.baidu.com/share/init?surl=T3-kS_FgYI6DeXv3n1I7bA<td>ih02<br></td></td></tr>
<tr>
<td>Eye Vessels (DRIVE dataset)<br></td><td>https://pan.baidu.com/share/init?surl=UkMLmdbM61N8ecgnKlAsPg<td>f1ek<br></td></td></tr>
<tr>
<td>Esophagus and Esophagus Cancer dataset (First Affiliated Hospital of Sun Yat-sen University)<br></td><td>https://pan.baidu.com/share/init?surl=0b5arIQjNpiggwdkgYNHXQ<td>hivm<br></td></td></tr>
</table>

<h4 id="为什么-Unet-在医疗图像分割中表现好"><a href="#为什么-Unet-在医疗图像分割中表现好" class="headerlink" title="为什么 Unet 在医疗图像分割中表现好?"></a>为什么 Unet 在医疗图像分割中表现好?</h4><p>大多数医疗影像语义分割任务都会首先用 Unet 作为 baseline，当然上一章节讲解的 Unet 的优点肯定是可以当作这个问题的答案，这里谈一谈医疗影像的特点</p>
<p>根据网友的讨论，得到的结果：</p>
<ol>
<li>医疗影像语义较为简单、结构固定。因此语义信息相比自动驾驶等较为单一，因此并不需要去筛选过滤无用的信息。医疗影像的所有特征都很重要，因此低级特征和高级语义特征都很重要，所以 U 型结构的 skip connection 结构（特征拼接）更好派上用场</li>
<li>医学影像的数据较少，获取难度大，数据量可能只有几百甚至不到 100，因此如果使用大型的网络例如 DeepLabv3+ 等模型，很容易过拟合。大型网络的优点是更强的图像表述能力，而较为简单、数量少的医学影像并没有那么多的内容需要表述，因此也有人发现在小数量级中，分割的 SOTA 模型与轻量的 Unet 并没有神恶魔优势</li>
<li>医学影像往往是多模态的。比方说 ISLES 脑梗竞赛中，官方提供了 CBF，MTT，CBV 等多中模态的数据（这一点听不懂也无妨）。因此医学影像任务中，往往需要自己设计网络去提取不同的模态特征，因此轻量结构简单的 Unet 可以有更大的操作空间。</li>
</ol>
<blockquote>
<p>Q:过拟合与模型复杂程度有关还和什么有关呢?</p>
</blockquote>
<h4 id="模型代码-1"><a href="#模型代码-1" class="headerlink" title="模型代码"></a>模型代码</h4><h5 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> autograd<br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> partial<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> models<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DoubleConv</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_ch, out_ch</span>):<br>        <span class="hljs-built_in">super</span>(DoubleConv, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.**conv** = nn.Sequential(<br>            nn.Conv2d(in_ch, out_ch, <span class="hljs-number">3</span>, _padding_=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(out_ch),<br>            nn.ReLU(_inplace_=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(out_ch, out_ch, <span class="hljs-number">3</span>, _padding_=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(out_ch),<br>            nn.ReLU(_inplace_=<span class="hljs-literal">True</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.**conv**(<span class="hljs-built_in">input</span>)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Unet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_ch, out_ch</span>):<br>        <span class="hljs-built_in">super</span>(Unet, <span class="hljs-variable language_">self</span>).__init__()<br><br>        <span class="hljs-variable language_">self</span>.**conv1** = DoubleConv(in_ch, <span class="hljs-number">32</span>)<br>        <span class="hljs-variable language_">self</span>.**pool1** = nn.MaxPool2d(<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.**conv2** = DoubleConv(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>)<br>        <span class="hljs-variable language_">self</span>.**pool2** = nn.MaxPool2d(<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.**conv3** = DoubleConv(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>)<br>        <span class="hljs-variable language_">self</span>.**pool3** = nn.MaxPool2d(<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.**conv4** = DoubleConv(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>)<br>        <span class="hljs-variable language_">self</span>.**pool4** = nn.MaxPool2d(<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.**conv5** = DoubleConv(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>)<br>        <span class="hljs-variable language_">self</span>.**up6** = nn.ConvTranspose2d(<span class="hljs-number">512</span>, <span class="hljs-number">256</span>, <span class="hljs-number">2</span>, _stride_=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.**conv6** = DoubleConv(<span class="hljs-number">512</span>, <span class="hljs-number">256</span>)<br>        <span class="hljs-variable language_">self</span>.**up7** = nn.ConvTranspose2d(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>, <span class="hljs-number">2</span>, _stride_=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.**conv7** = DoubleConv(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>)<br>        <span class="hljs-variable language_">self</span>.**up8** = nn.ConvTranspose2d(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>, <span class="hljs-number">2</span>, _stride_=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.**conv8** = DoubleConv(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>)<br>        <span class="hljs-variable language_">self</span>.**up9** = nn.ConvTranspose2d(<span class="hljs-number">64</span>, <span class="hljs-number">32</span>, <span class="hljs-number">2</span>, _stride_=<span class="hljs-number">2</span>)<br>        <span class="hljs-variable language_">self</span>.**conv9** = DoubleConv(<span class="hljs-number">64</span>, <span class="hljs-number">32</span>)<br>        <span class="hljs-variable language_">self</span>.**conv10** = nn.Conv2d(<span class="hljs-number">32</span>, out_ch, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        _<span class="hljs-comment">#print(x.shape)_</span><br>        c1 = <span class="hljs-variable language_">self</span>.**conv1**(x)<br>        p1 = <span class="hljs-variable language_">self</span>.**pool1**(c1)<br>        _<span class="hljs-comment">#print(p1.shape)_</span><br>        c2 = <span class="hljs-variable language_">self</span>.**conv2**(p1)<br>        p2 = <span class="hljs-variable language_">self</span>.**pool2**(c2)<br>        _<span class="hljs-comment">#print(p2.shape)_</span><br>        c3 = <span class="hljs-variable language_">self</span>.**conv3**(p2)<br>        p3 = <span class="hljs-variable language_">self</span>.**pool3**(c3)<br>        _<span class="hljs-comment">#print(p3.shape)_</span><br>        c4 = <span class="hljs-variable language_">self</span>.**conv4**(p3)<br>        p4 = <span class="hljs-variable language_">self</span>.**pool4**(c4)<br>        _<span class="hljs-comment">#print(p4.shape)_</span><br>        c5 = <span class="hljs-variable language_">self</span>.**conv5**(p4)<br>        up_6 = <span class="hljs-variable language_">self</span>.**up6**(c5)<br>        merge6 = torch.cat([up_6, c4], _dim_=<span class="hljs-number">1</span>)<br>        c6 = <span class="hljs-variable language_">self</span>.**conv6**(merge6)<br>        up_7 = <span class="hljs-variable language_">self</span>.**up7**(c6)<br>        merge7 = torch.cat([up_7, c3], _dim_=<span class="hljs-number">1</span>)<br>        c7 = <span class="hljs-variable language_">self</span>.**conv7**(merge7)<br>        up_8 = <span class="hljs-variable language_">self</span>.**up8**(c7)<br>        merge8 = torch.cat([up_8, c2], _dim_=<span class="hljs-number">1</span>)<br>        c8 = <span class="hljs-variable language_">self</span>.**conv8**(merge8)<br>        up_9 = <span class="hljs-variable language_">self</span>.**up9**(c8)<br>        merge9 = torch.cat([up_9, c1], _dim_=<span class="hljs-number">1</span>)<br>        c9 = <span class="hljs-variable language_">self</span>.**conv9**(merge9)<br>        c10 = <span class="hljs-variable language_">self</span>.**conv10**(c9)<br>        out = nn.Sigmoid()(c10)<br>        <span class="hljs-keyword">return</span> out<br><br>nonlinearity = partial(F.relu, _inplace_=<span class="hljs-literal">True</span>)<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DecoderBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, n_filters</span>):<br>        <span class="hljs-built_in">super</span>(DecoderBlock, <span class="hljs-variable language_">self</span>).__init__()<br><br>        <span class="hljs-variable language_">self</span>.**conv1** = nn.Conv2d(in_channels, in_channels // <span class="hljs-number">4</span>, <span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>.**norm1** = nn.BatchNorm2d(in_channels // <span class="hljs-number">4</span>)<br>        <span class="hljs-variable language_">self</span>.**relu1** = nonlinearity<br><br>        <span class="hljs-variable language_">self</span>.**deconv2** = nn.ConvTranspose2d(in_channels // <span class="hljs-number">4</span>, in_channels // <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, _stride_=<span class="hljs-number">2</span>, _padding_=<span class="hljs-number">1</span>, _output_padding_=<span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>.**norm2** = nn.BatchNorm2d(in_channels // <span class="hljs-number">4</span>)<br>        <span class="hljs-variable language_">self</span>.**relu2** = nonlinearity<br><br>        <span class="hljs-variable language_">self</span>.**conv3** = nn.Conv2d(in_channels // <span class="hljs-number">4</span>, n_filters, <span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>.**norm3** = nn.BatchNorm2d(n_filters)<br>        <span class="hljs-variable language_">self</span>.**relu3** = nonlinearity<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.**conv1**(x)<br>        x = <span class="hljs-variable language_">self</span>.**norm1**(x)<br>        x = <span class="hljs-variable language_">self</span>.**relu1**(x)<br>        x = <span class="hljs-variable language_">self</span>.**deconv2**(x)<br>        x = <span class="hljs-variable language_">self</span>.**norm2**(x)<br>        x = <span class="hljs-variable language_">self</span>.**relu2**(x)<br>        x = <span class="hljs-variable language_">self</span>.**conv3**(x)<br>        x = <span class="hljs-variable language_">self</span>.**norm3**(x)<br>        x = <span class="hljs-variable language_">self</span>.**relu3**(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">resnet34_unet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_classes=<span class="hljs-number">1</span>, num_channels=<span class="hljs-number">3</span>,pretrained=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>(resnet34_unet, <span class="hljs-variable language_">self</span>).__init__()<br><br>        filters = [<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>]<br>        resnet = models.resnet34(_pretrained_=pretrained)<br>        <span class="hljs-variable language_">self</span>.**firstconv** = resnet.**conv1**<br>        <span class="hljs-variable language_">self</span>.**firstbn** = resnet.**bn1**<br>        <span class="hljs-variable language_">self</span>.**firstrelu** = resnet.**relu**<br>        <span class="hljs-variable language_">self</span>.**firstmaxpool** = resnet.**maxpool**<br>        <span class="hljs-variable language_">self</span>.**encoder1** = resnet.**layer1**<br>        <span class="hljs-variable language_">self</span>.**encoder2** = resnet.**layer2**<br>        <span class="hljs-variable language_">self</span>.**encoder3** = resnet.**layer3**<br>        <span class="hljs-variable language_">self</span>.**encoder4** = resnet.**layer4**<br><br>        <span class="hljs-variable language_">self</span>.**decoder4** = DecoderBlock(<span class="hljs-number">512</span>, filters[<span class="hljs-number">2</span>])<br>        <span class="hljs-variable language_">self</span>.**decoder3** = DecoderBlock(filters[<span class="hljs-number">2</span>], filters[<span class="hljs-number">1</span>])<br>        <span class="hljs-variable language_">self</span>.**decoder2** = DecoderBlock(filters[<span class="hljs-number">1</span>], filters[<span class="hljs-number">0</span>])<br>        <span class="hljs-variable language_">self</span>.**decoder1** = DecoderBlock(filters[<span class="hljs-number">0</span>], filters[<span class="hljs-number">0</span>])<br><br>        <span class="hljs-variable language_">self</span>.**decoder4** = DecoderBlock(<span class="hljs-number">512</span>, filters[<span class="hljs-number">2</span>])<br>        <span class="hljs-variable language_">self</span>.**decoder3** = DecoderBlock(filters[<span class="hljs-number">2</span>], filters[<span class="hljs-number">1</span>])<br>        <span class="hljs-variable language_">self</span>.**decoder2** = DecoderBlock(filters[<span class="hljs-number">1</span>], filters[<span class="hljs-number">0</span>])<br>        <span class="hljs-variable language_">self</span>.**decoder1** = DecoderBlock(filters[<span class="hljs-number">0</span>], filters[<span class="hljs-number">0</span>])<br><br>        <span class="hljs-variable language_">self</span>.**finaldeconv1** = nn.ConvTranspose2d(filters[<span class="hljs-number">0</span>], <span class="hljs-number">32</span>, <span class="hljs-number">4</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>.**finalrelu1** = nonlinearity<br>        <span class="hljs-variable language_">self</span>.**finalconv2** = nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">3</span>, _padding_=<span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>.**finalrelu2** = nonlinearity<br>        <span class="hljs-variable language_">self</span>.**finalconv3** = nn.Conv2d(<span class="hljs-number">32</span>, num_classes, <span class="hljs-number">3</span>, _padding_=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        _<span class="hljs-comment"># Encoder_</span><br>        x = <span class="hljs-variable language_">self</span>.**firstconv**(x)<br>        x = <span class="hljs-variable language_">self</span>.**firstbn**(x)<br>        x = <span class="hljs-variable language_">self</span>.**firstrelu**(x)<br>        x = <span class="hljs-variable language_">self</span>.**firstmaxpool**(x)<br>        e1 = <span class="hljs-variable language_">self</span>.**encoder1**(x)<br>        e2 = <span class="hljs-variable language_">self</span>.**encoder2**(e1)<br>        e3 = <span class="hljs-variable language_">self</span>.**encoder3**(e2)<br>        e4 = <span class="hljs-variable language_">self</span>.**encoder4**(e3)<br><br>        _<span class="hljs-comment"># Center_</span><br><br>        _<span class="hljs-comment"># Decoder_</span><br>        d4 = <span class="hljs-variable language_">self</span>.**decoder4**(e4) + e3<br>        d3 = <span class="hljs-variable language_">self</span>.**decoder3**(d4) + e2<br>        d2 = <span class="hljs-variable language_">self</span>.**decoder2**(d3) + e1<br>        d1 = <span class="hljs-variable language_">self</span>.**decoder1**(d2)<br><br>        out = <span class="hljs-variable language_">self</span>.**finaldeconv1**(d1)<br>        out = <span class="hljs-variable language_">self</span>.**finalrelu1**(out)<br>        out = <span class="hljs-variable language_">self</span>.**finalconv2**(out)<br>        out = <span class="hljs-variable language_">self</span>.**finalrelu2**(out)<br>        out = <span class="hljs-variable language_">self</span>.**finalconv3**(out)<br><br>        <span class="hljs-keyword">return</span> nn.Sigmoid()(out)<br></code></pre></td></tr></table></figure>

<h5 id="模型实现"><a href="#模型实现" class="headerlink" title="模型实现"></a>模型实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">double_conv2d_bn</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,in_channels,out_channels,kernel_size=<span class="hljs-number">3</span>,strides=<span class="hljs-number">1</span>,padding=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>(double_conv2d_bn,<span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.conv1 = nn.Conv2d(in_channels,out_channels,<br>                               kernel_size=kernel_size,<br>                              stride = strides,padding=padding,bias=<span class="hljs-literal">True</span>)<br>        <span class="hljs-variable language_">self</span>.conv2 = nn.Conv2d(out_channels,out_channels,<br>                              kernel_size = kernel_size,<br>                              stride = strides,padding=padding,bias=<span class="hljs-literal">True</span>)<br>        <span class="hljs-variable language_">self</span>.bn1 = nn.BatchNorm2d(out_channels)<br>        <span class="hljs-variable language_">self</span>.bn2 = nn.BatchNorm2d(out_channels)<br>  <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        out = F.relu(<span class="hljs-variable language_">self</span>.bn1(<span class="hljs-variable language_">self</span>.conv1(x)))<br>        out = F.relu(<span class="hljs-variable language_">self</span>.bn2(<span class="hljs-variable language_">self</span>.conv2(out)))<br>        <span class="hljs-keyword">return</span> out<br>  <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">deconv2d_bn</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,in_channels,out_channels,kernel_size=<span class="hljs-number">2</span>,strides=<span class="hljs-number">2</span></span>):<br>        <span class="hljs-built_in">super</span>(deconv2d_bn,<span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.conv1 = nn.ConvTranspose2d(in_channels,out_channels,<br>                                        kernel_size = kernel_size,<br>                                       stride = strides,bias=<span class="hljs-literal">True</span>)<br>        <span class="hljs-variable language_">self</span>.bn1 = nn.BatchNorm2d(out_channels)<br>      <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        out = F.relu(<span class="hljs-variable language_">self</span>.bn1(<span class="hljs-variable language_">self</span>.conv1(x)))<br>        <span class="hljs-keyword">return</span> out<br>  <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Unet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Unet,<span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.layer1_conv = double_conv2d_bn(<span class="hljs-number">1</span>,<span class="hljs-number">8</span>)<br>        <span class="hljs-variable language_">self</span>.layer2_conv = double_conv2d_bn(<span class="hljs-number">8</span>,<span class="hljs-number">16</span>)<br>        <span class="hljs-variable language_">self</span>.layer3_conv = double_conv2d_bn(<span class="hljs-number">16</span>,<span class="hljs-number">32</span>)<br>        <span class="hljs-variable language_">self</span>.layer4_conv = double_conv2d_bn(<span class="hljs-number">32</span>,<span class="hljs-number">64</span>)<br>        <span class="hljs-variable language_">self</span>.layer5_conv = double_conv2d_bn(<span class="hljs-number">64</span>,<span class="hljs-number">128</span>)<br>        <span class="hljs-variable language_">self</span>.layer6_conv = double_conv2d_bn(<span class="hljs-number">128</span>,<span class="hljs-number">64</span>)<br>        <span class="hljs-variable language_">self</span>.layer7_conv = double_conv2d_bn(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>)<br>        <span class="hljs-variable language_">self</span>.layer8_conv = double_conv2d_bn(<span class="hljs-number">32</span>,<span class="hljs-number">16</span>)<br>        <span class="hljs-variable language_">self</span>.layer9_conv = double_conv2d_bn(<span class="hljs-number">16</span>,<span class="hljs-number">8</span>)<br>        <span class="hljs-variable language_">self</span>.layer10_conv = nn.Conv2d(<span class="hljs-number">8</span>,<span class="hljs-number">1</span>,kernel_size=<span class="hljs-number">3</span>,<br>                                     stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">1</span>,bias=<span class="hljs-literal">True</span>)<br>      <br>        <span class="hljs-variable language_">self</span>.deconv1 = deconv2d_bn(<span class="hljs-number">128</span>,<span class="hljs-number">64</span>)<br>        <span class="hljs-variable language_">self</span>.deconv2 = deconv2d_bn(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>)<br>        <span class="hljs-variable language_">self</span>.deconv3 = deconv2d_bn(<span class="hljs-number">32</span>,<span class="hljs-number">16</span>)<br>        <span class="hljs-variable language_">self</span>.deconv4 = deconv2d_bn(<span class="hljs-number">16</span>,<span class="hljs-number">8</span>)<br>      <br>        <span class="hljs-variable language_">self</span>.sigmoid = nn.Sigmoid()<br>      <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        conv1 = <span class="hljs-variable language_">self</span>.layer1_conv(x)<br>        pool1 = F.max_pool2d(conv1,<span class="hljs-number">2</span>)<br>      <br>        conv2 = <span class="hljs-variable language_">self</span>.layer2_conv(pool1)<br>        pool2 = F.max_pool2d(conv2,<span class="hljs-number">2</span>)<br>      <br>        conv3 = <span class="hljs-variable language_">self</span>.layer3_conv(pool2)<br>        pool3 = F.max_pool2d(conv3,<span class="hljs-number">2</span>)<br>      <br>        conv4 = <span class="hljs-variable language_">self</span>.layer4_conv(pool3)<br>        pool4 = F.max_pool2d(conv4,<span class="hljs-number">2</span>)<br>      <br>        conv5 = <span class="hljs-variable language_">self</span>.layer5_conv(pool4)<br>      <br>        convt1 = <span class="hljs-variable language_">self</span>.deconv1(conv5)<br>        concat1 = torch.cat([convt1,conv4],dim=<span class="hljs-number">1</span>)<br>        conv6 = <span class="hljs-variable language_">self</span>.layer6_conv(concat1)<br>      <br>        convt2 = <span class="hljs-variable language_">self</span>.deconv2(conv6)<br>        concat2 = torch.cat([convt2,conv3],dim=<span class="hljs-number">1</span>)<br>        conv7 = <span class="hljs-variable language_">self</span>.layer7_conv(concat2)<br>      <br>        convt3 = <span class="hljs-variable language_">self</span>.deconv3(conv7)<br>        concat3 = torch.cat([convt3,conv2],dim=<span class="hljs-number">1</span>)<br>        conv8 = <span class="hljs-variable language_">self</span>.layer8_conv(concat3)<br>      <br>        convt4 = <span class="hljs-variable language_">self</span>.deconv4(conv8)<br>        concat4 = torch.cat([convt4,conv1],dim=<span class="hljs-number">1</span>)<br>        conv9 = <span class="hljs-variable language_">self</span>.layer9_conv(concat4)<br>        outp = <span class="hljs-variable language_">self</span>.layer10_conv(conv9)<br>        outp = <span class="hljs-variable language_">self</span>.sigmoid(outp)<br>        <span class="hljs-keyword">return</span> outp<br>  <br><br>model = Unet()<br>inp = torch.rand(<span class="hljs-number">10</span>,<span class="hljs-number">1</span>,<span class="hljs-number">224</span>,<span class="hljs-number">224</span>)<br>outp = model(inp)<br><span class="hljs-built_in">print</span>(outp.shape)<br>==&gt; torch.Size([<span class="hljs-number">10</span>, <span class="hljs-number">1</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>])<br></code></pre></td></tr></table></figure>

<h4 id="相关资源-1"><a href="#相关资源-1" class="headerlink" title="相关资源"></a>相关资源</h4><h5 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h5><blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/Andy-zhujunwen/UNET-ZOO?tab=readme-ov-file%60">https://github.com/Andy-zhujunwen/UNET-ZOO?tab=readme-ov-file`</a><br><code> https://github.com/bigmb/Unet-Segmentation-Pytorch-Nest-of-Unets</code><br><code> https://www.codewithgpu.com/i/bubbliiiing/unet-pytorch/UNet-PyTorch</code><br>`<br><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/h2chen/demo_unet">https://huggingface.co/spaces/h2chen/demo_unet</a></p>
</blockquote>
<h5 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h5><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45074568/article/details/114901600">UNet详解（附图文和代码实现）-CSDN博客</a><code>&lt;br&gt;</code><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/PythonLearner/p/14041874.html">图像分割必备知识点 | Unet详解 理论+ 代码 - 忽逢桃林 - 博客园</a></p>
</blockquote>
<hr>

        </article>
        <section class="post-near">
            <ul>
                
                    <li>上一篇: <a href="/2025/02/16/2025-02-16-%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2/">实例分割</a></li>
                
                
                    <li>下一篇: <a href="/2025/02/11/2025-02-11-%E6%95%B0%E6%A8%A1%E7%AC%94%E8%AE%B0_%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E4%B8%8E%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B/">2025-02-11-数模笔记_微分方程与差分方程</a></li>
                
            </ul>
        </section>
        
            <section class="post-tags">
            <a class="-none-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a>
            </section>
        
    
        <section class="post-author">
        
            <figure class="author-avatar">
                <img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/20250927100251272.jpg?imageSlim" alt="ttkqwe" />
            </figure>
        
            <div class="author-info">
                <h4>ttkqwe</h4>
                <p>计算机大三学生，喜欢研究一些乱七八糟的东西，目前研究方向是深度学习。本站未注明转载的文章均为原创，并采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="nofollow">CC BY-NC-SA 4.0</a> 授权协议，<span style="color: #E91E63">转载请注明来源</span>，谢谢！如本站内容对你有所帮助的话，不妨 <a target="_blank" rel="noopener" href="https://paul.ren/donate">捐助支持</a> 一下？同时欢迎订阅关注 <a href="https://paul.ren/note" target="_blank">我的日记</a>，唠嗑（分享）每日的折腾经历。</p>
            </div>
        </section>
    
    </div>
</main>

    <footer>
    <div class="buttons">
        <button class="to-top" href="#"></button>
    </div>
    <div class="wrap min">
        <section class="widget">
            <div class="row">
                <div class="col-m-4">
                    <h3 class="title-recent">最新文章：</h3>
                    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/07/29/2025-07-29-%E4%B9%9D%E6%A0%BC%E9%80%9A%E7%94%A8%E5%9F%BA%E7%A1%80%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/">2025-07-29-九格通用基础大模型环境配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/07/03/2025-07-03-%E6%8B%AF%E6%95%91%E6%88%91%E7%9A%84%E2%80%9C%E9%AB%98%E7%83%A7%E2%80%9D%E6%88%98%E5%8F%8B%E2%80%94%E2%80%94Y7000P%202024%E7%89%88%E6%B8%85%E7%81%B0%E6%8D%A2%E7%A1%85%E8%84%82%E8%AE%B0%E5%BD%95/">2025-07-03-拯救我的“高烧”战友——Y7000P 2024 版清灰换硅脂记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/06/08/2025-06-08-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%95%E5%B1%82%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/">2025-06-08-大模型底层技术分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/06/05/2025-06-05-%E6%99%BA%E8%83%BD%E4%BD%93%E5%B9%B3%E5%8F%B0%E5%8F%8A%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/">2025-06-05-智能体平台及关键技术分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/06/04/2025-06-04-%E4%BD%8E%E4%BB%A3%E7%A0%81%E5%B9%B3%E5%8F%B0%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF%E4%BB%8B%E7%BB%8D/">2025-06-04-低代码平台及相关技术介绍应用</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/06/03/2025-06-03-%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/">2025-06-03-微信小程序开发框架详解</a></li></ul>
                </div>
                <div class="col-m-4">
                    <h3 class="title-date">时光机：</h3>
                    <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/07/">七月 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">六月 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/05/">五月 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/04/">四月 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">三月 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">二月 2025</a></li></ul>
                </div>
                <div class="col-m-4">
                    <h3 class="title-tags">标签云：</h3>
                    <a href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" style="font-size: 10px;">数学建模</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 14px;">深度学习</a> <a href="/tags/%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91/" style="font-size: 18px;">程序开发</a> <a href="/tags/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">算法学习</a> <a href="/tags/%E7%AE%97%E6%B3%95%E7%BB%83%E4%B9%A0/" style="font-size: 16px;">算法练习</a> <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" style="font-size: 12px;">论文阅读</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">课程学习</a> <a href="/tags/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/" style="font-size: 18px;">问题解决</a>
                </div>
            </div>
        </section>
        <section class="sub-footer">
            <p>© 2025 <a href="/">TK的小站</a>. All Rights Reserved. Theme By <a href="https://github.com/Dreamer-Paul/Hingle" target="_blank" rel="nofollow">Hingle</a>.</p>
        </section>
    </div>
</footer>


<script src="/static/kico.js"></script>
<script src="/static/hingle.js"></script>


<script>var hingle = new Paul_Hingle({"copyright":true,"night":true});</script>

  </body>
</html>
