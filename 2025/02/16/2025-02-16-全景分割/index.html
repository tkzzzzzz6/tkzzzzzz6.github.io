<!DOCTYPE html>
<html lang="zh">
  <head>
    
    <meta charset="UTF-8">
    <title>2025-02-16-全景分割 - TK的小站</title>
    <link rel="shortcut icon" href="/static/img/icon.png">
    <link rel="icon" href="/static/img/icon.png" sizes="192x192"/>
    
<link rel="stylesheet" href="/static/kico.css">
<link rel="stylesheet" href="/static/hingle.css">

    
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <meta property="og:site_name" content="TK的小站">
    <meta property="og:title" content="2025-02-16-全景分割"/>
    
    <style>body:before{ content: ''; background-image: url(https://api.paugram.com/wallpaper?source=gh) }</style>
    
<meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="TK的小站" type="application/atom+xml">
</head>

  <body>
    <header>
    <div class="head-title">
        <h4>TK的小站</h4>
    </div>
    <div class="head-action">
        <div class="toggle-btn"></div>
        <div class="light-btn"></div>
        <div class="search-btn"></div>
    </div>
    <form class="head-search" method="post">
        <input type="text" name="s" placeholder="搜索什么？">
    </form>
    <nav class="head-menu">
        <a href="/">首页</a>
        <div class="has-child">
            <a href>分类</a>
            <div class="sub-menu">
                <a class="category-link" href="/categories/%E8%BF%9B%E5%87%BB%E7%9A%84%E7%A0%81%E5%86%9C/">进击的码农</a>
            </div>
        </div>
        
            <a href="/about">关于我</a>
        
            <a href="/friends">朋友们</a>
        
            <a href="/tools">工具推荐</a>
        
    </nav>
</header>

    <main>
    <div class="wrap min">
        <section class="post-title">
            <h2>2025-02-16-全景分割</h2>
            <div class="post-meta">
                <time class="date">2025.02.16</time>
            
            </div>
        </section>
        <article class="post-content">
        
            <blockquote>这篇文章上次修改于 237 天前，可能其部分内容已经发生变化，如有疑问可询问作者。</blockquote>
        
            <h1 id="全景分割（Panoptic-Segmentation）"><a href="#全景分割（Panoptic-Segmentation）" class="headerlink" title="全景分割（Panoptic Segmentation）"></a><strong>全景分割（Panoptic Segmentation）</strong></h1><h2 id="定义"><a href="#定义" class="headerlink" title="** 定义**"></a>** 定义**</h2><p>全景分割是语义分割和实例分割的结合。它要求对图像中的每个像素分配一个语义标签，并识别出单独的对象实例。全景分割的目标是提供一个连贯、丰富和完整的场景分割。</p>
<p><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/17404074366431740407436111.png" alt="17404074366431740407436111.png"></p>
<ol>
<li><p><strong>统一处理“Things”和“Stuff”</strong>：</p>
<ul>
<li><strong>Things</strong>（可数目标）：如人、动物、车辆等，需要检测并区分每个实例。</li>
<li><strong>Stuff</strong>（不可数目标）：如天空、草地、道路等，只需进行语义分割。<br>全景分割通过为每个像素分配类别和实例 ID，同时处理这两种类型的目标。</li>
</ul>
</li>
<li><p><strong>提供完整的场景理解</strong>：<br>全景分割不仅关注前景目标的分割和识别，还涵盖了背景区域的语义理解，从而生成连贯且完整的场景分割。</p>
</li>
<li><p><strong>解决语义分割和实例分割的局限性</strong>：</p>
<ul>
<li>语义分割无法区分同一类别中的不同实例。</li>
<li>实例分割仅关注前景目标，且分割结果可能重叠。<br>全景分割通过统一的格式和度量，克服了这些局限性。</li>
</ul>
</li>
</ol>
<h2 id="特点"><a href="#特点" class="headerlink" title="** 特点**"></a>** 特点**</h2><ul>
<li>同时处理“物体”（如人、车辆）和“非物体”（如草地、天空）区域。</li>
<li>输出格式为每个像素分配一个语义标签和一个唯一的实例标识符。</li>
</ul>
<h2 id="应用"><a href="#应用" class="headerlink" title="** 应用**"></a>** 应用**</h2><p>全景分割在以下领域有重要应用：</p>
<ul>
<li><strong>自动驾驶</strong>：提供全面的场景理解，包括车辆、行人和背景。</li>
<li><strong>增强现实</strong>：用于构建虚拟与现实融合的场景。</li>
<li><strong>场景解析</strong>：用于复杂场景的全面理解。</li>
</ul>
<h2 id="常见模型"><a href="#常见模型" class="headerlink" title="** 常见模型**"></a>** 常见模型**</h2><h3 id="Mask2Former"><a href="#Mask2Former" class="headerlink" title="Mask2Former"></a><strong>Mask2Former</strong></h3><ul>
<li><strong>优点</strong>：统一框架，能够处理语义、实例和全景分割任务，高精度。</li>
<li><strong>缺点</strong>：基于 Transformer 的架构复杂，训练难度大，资源密集型。</li>
</ul>
<h4 id="提出初衷"><a href="#提出初衷" class="headerlink" title="提出初衷"></a>提出初衷</h4><p>Mask2Former 的提出初衷是为了进一步改进 MaskFormer 的性能，并解决其在实例分割任务中的不足。MaskFormer 虽然在多个分割任务上取得了不错的结果，但在实例分割任务上与当时的 SOTA 模型仍有较大差距,Mask2Former 的主要动机和改进点如下：</p>
<ol>
<li><strong>引入掩码注意力（Masked Attention）</strong>：Mask2Former 将交叉注意力限制在预测的掩码区域内，而不是关注整个特征图。这种局部注意力机制能够更高效地提取目标特征，同时减少计算量。</li>
<li><strong>多尺度高分辨率特征</strong>：为了更好地处理小目标，Mask2Former 利用多尺度特征金字塔，并将不同分辨率的特征分别输入到 Transformer 解码器的不同层中。这一改进显著提升了对小目标的分割性能。</li>
<li><strong>优化训练过程</strong>：Mask2Former 对 Transformer 解码器进行了多项优化，包括调整自注意力和交叉注意力的顺序、使查询特征（query embedding）可学习、移除 dropout 等。这些改进在不增加计算开销的情况下提升了模型性能。</li>
<li><strong>重要性采样（Importance Sampling）</strong>：Mask2Former 在计算损失时，采用随机采样的方式，仅在部分像素点上计算损失，而不是在整个图像上计算。这一策略加快了训练速度。</li>
<li><strong>通用性与高效性</strong>：Mask2Former 的目标是提供一个通用的图像分割框架，能够同时处理语义分割、实例分割和全景分割任务。相比为每个任务设计专门的模型，Mask2Former 显著减少了研究工作量，并在多个数据集上达到了 SOTA 性能。<br><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/1740407397648HwWrbOxAeoarRyxEZ8vckW7Snif.png" alt="1740407397648HwWrbOxAeoarRyxEZ8vckW7Snif.png"></li>
</ol>
<h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/1740407421645ZhT6bgJLvom4n8xIAnzcdyG1n2b.png" alt="1740407421645ZhT6bgJLvom4n8xIAnzcdyG1n2b.png"><br>Mask2Former 是一种通用的图像分割架构，能够同时处理全景分割、实例分割和语义分割任务。其网络结构主要由以下三个核心部分组成：</p>
<h3 id="1-Backbone（骨干网络）"><a href="#1-Backbone（骨干网络）" class="headerlink" title="1. Backbone（骨干网络）"></a>1. <strong>Backbone（骨干网络）</strong></h3><p>骨干网络用于从输入图像中提取低分辨率的特征图。Mask2Former 可以使用多种流行的骨干网络，例如 ResNet 或 Swin Transformer。这些特征图将被传递到后续模块以进行进一步处理。</p>
<h3 id="2-Pixel-Decoder（像素解码器）"><a href="#2-Pixel-Decoder（像素解码器）" class="headerlink" title="2. Pixel Decoder（像素解码器）"></a>2. <strong>Pixel Decoder（像素解码器）</strong></h3><p>像素解码器的作用是将骨干网络提取的低分辨率特征逐步上采样到高分辨率特征图。这一模块通过多尺度特征金字塔处理不同分辨率的特征，并生成高分辨率的逐像素特征嵌入。例如，Mask2Former 使用了多尺度可变形注意力（MSDeformAttn）作为像素解码器的结构，处理 1/8、1/16、1/32 大小的特征图，并通过上采样生成 1/4 分辨率的特征图。</p>
<h3 id="3-Transformer-Decoder（Transformer-解码器）"><a href="#3-Transformer-Decoder（Transformer-解码器）" class="headerlink" title="3. Transformer Decoder（Transformer 解码器）"></a>3. <strong>Transformer Decoder（Transformer 解码器）</strong></h3><p>Transformer 解码器是 Mask2Former 的核心模块，负责处理对象查询（object queries）并生成最终的分割掩码。Mask2Former 引入了掩码注意力（masked attention），将交叉注意力的范围限制在预测的掩码区域内，从而提取局部特征。此外，解码器还进行了多项优化：</p>
<ul>
<li><strong>掩码注意力</strong>：通过限制交叉注意力的范围，提高模型对小目标的分割性能。</li>
<li><strong>多尺度特征利用</strong>：将不同分辨率的特征分别输入到 Transformer 解码器的不同层中，以更好地处理小目标。</li>
<li><strong>优化训练过程</strong>：调整自注意力和交叉注意力的顺序，使查询特征可学习，并移除 dropout，从而提高计算效率。</li>
</ul>
<h3 id="4-损失计算"><a href="#4-损失计算" class="headerlink" title="4. 损失计算"></a>4. <strong>损失计算</strong></h3><p>Mask2Former 在训练时采用了一种高效的损失计算方式。它通过随机采样点计算掩码损失，而不是在整个掩码上计算损失。具体来说：</p>
<ul>
<li><strong>匹配损失（Matching Loss）</strong>：在 Transformer 预测类别时，采用均匀采样计算损失。</li>
<li><strong>最终损失（Final Loss）</strong>：采用重要性采样（importance sampling），针对不同的预测结果采样不同的点计算损失。这种策略显著减少了显存占用，提高了训练效率。</li>
</ul>
<blockquote>
<p>Q:<strong>Mask2Former 是如何通过掩码注意力（Masked Attention）提升实例分割性能的呢？</strong></p>
</blockquote>
<h4 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h4><h5 id="项目"><a href="#项目" class="headerlink" title="项目"></a><strong>项目</strong></h5><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/Mask2Former?tab=readme-ov-file">facebookresearch/Mask2Former: Code release for "Masked-attention Mask Transformer for Universal Image Segmentation"</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/hugging-fellows/mask2former-demo">Mask2former Demo - a Hugging Face Space by hugging-fellows</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/zzubqh/Mask2Former-Simplify?tab=readme-ov-file">zzubqh/Mask2Former-Simplify</a></li>
<li><a target="_blank" rel="noopener" href="https://bowenc0221.github.io/maskformer/">https://bowenc0221.github.io/maskformer/</a></li>
</ol>
<h5 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h5><ol>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/wzk4869/article/details/131378109">【计算机视觉】MaskFormer:将语义分割和实例分割作为同一任务进行训练_语义分割标签作为输入-CSDN 博客</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/theseventhson/p/18513038">LLM 大模型: Maskformer/Mask2Former 语义分割原理详解 - 第七子 007 - 博客园</a></li>
</ol>
<h5 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h5><ol>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.01527">[2112.01527] Masked-attention Mask Transformer for Universal Image Segmentation</a></li>
</ol>
<hr>

        </article>
        <section class="post-near">
            <ul>
                
                    <li>上一篇: <a href="/2025/02/17/2025-02-17-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E3%80%81%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2%E4%B8%8E%E5%85%A8%E6%99%AF%E5%88%86%E5%89%B2%E4%B8%89%E7%A7%8D%E5%88%86%E5%89%B2%E6%8A%80%E6%9C%AF%E7%9A%84%E5%AF%B9%E6%AF%94/">语义分割、实例分割与全景分割三种分割技术的对比</a></li>
                
                
                    <li>下一篇: <a href="/2025/02/16/2025-02-16-%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2/">实例分割</a></li>
                
            </ul>
        </section>
        
            <section class="post-tags">
            <a class="-none-link" href="/tags/deep-learning/" rel="tag">深度学习</a>
            </section>
        
    
        <section class="post-author">
        
            <figure class="author-avatar">
                <img src="https://tk-pichost-1325224430.cos.ap-chengdu.myqcloud.com/blog/20250927100251272.jpg?imageSlim" alt="ttkqwe" />
            </figure>
        
            <div class="author-info">
                <h4>ttkqwe</h4>
                <p>计算机大三学生，喜欢研究一些乱七八糟的东西，目前研究方向是深度学习。本站未注明转载的文章均为原创，并采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="nofollow">CC BY-NC-SA 4.0</a> 授权协议，<span style="color: #E91E63">转载请注明来源</span>，谢谢！</p>
            </div>
        </section>
    
    </div>
</main>

    <footer>
    <div class="buttons">
        <button class="to-top" href="#"></button>
    </div>
    <div class="wrap min">
        <section class="widget">
            <div class="row">
                <div class="col-m-4">
                    <h3 class="title-recent">最新文章：</h3>
                    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2025/07/29/2025-07-29-%E4%B9%9D%E6%A0%BC%E9%80%9A%E7%94%A8%E5%9F%BA%E7%A1%80%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/">2025-07-29-九格通用基础大模型环境配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/07/03/2025-07-03-%E6%8B%AF%E6%95%91%E6%88%91%E7%9A%84%E2%80%9C%E9%AB%98%E7%83%A7%E2%80%9D%E6%88%98%E5%8F%8B%E2%80%94%E2%80%94Y7000P%202024%E7%89%88%E6%B8%85%E7%81%B0%E6%8D%A2%E7%A1%85%E8%84%82%E8%AE%B0%E5%BD%95/">2025-07-03-拯救我的“高烧”战友——Y7000P 2024 版清灰换硅脂记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/06/08/2025-06-08-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%95%E5%B1%82%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/">2025-06-08-大模型底层技术分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/06/05/2025-06-05-%E6%99%BA%E8%83%BD%E4%BD%93%E5%B9%B3%E5%8F%B0%E5%8F%8A%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/">2025-06-05-智能体平台及关键技术分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/06/04/2025-06-04-%E4%BD%8E%E4%BB%A3%E7%A0%81%E5%B9%B3%E5%8F%B0%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF%E4%BB%8B%E7%BB%8D/">2025-06-04-低代码平台及相关技术介绍应用</a></li><li class="post-list-item"><a class="post-list-link" href="/2025/06/03/2025-06-03-%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/">2025-06-03-微信小程序开发框架详解</a></li></ul>
                </div>
                <div class="col-m-4">
                    <h3 class="title-date">时光机：</h3>
                    <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/07/">七月 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">六月 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/05/">五月 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/04/">四月 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">三月 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">二月 2025</a></li></ul>
                </div>
                <div class="col-m-4">
                    <h3 class="title-tags">标签云：</h3>
                    <a href="/tags/mathematical-modeling/" style="font-size: 10px;">数学建模</a> <a href="/tags/deep-learning/" style="font-size: 14px;">深度学习</a> <a href="/tags/development/" style="font-size: 18px;">程序开发</a> <a href="/tags/algorithm/" style="font-size: 10px;">算法学习</a> <a href="/tags/algorithm-practice/" style="font-size: 16px;">算法练习</a> <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" style="font-size: 12px;">论文阅读</a> <a href="/tags/course/" style="font-size: 20px;">课程学习</a> <a href="/tags/troubleshooting/" style="font-size: 18px;">问题解决</a>
                </div>
            </div>
        </section>
        <section class="sub-footer">
            <p>
                © 2025 <a href="/">TK的小站</a>. All Rights Reserved. Theme By <a href="https://github.com/Dreamer-Paul/Hingle" target="_blank" rel="nofollow">Hingle</a>.
                
                    &nbsp;|&nbsp;
                    <a href="https://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
                        蜀ICP备2025165253号
                    </a>
                
                
                    &nbsp;|&nbsp;
                    <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11000002000001" target="_blank" rel="nofollow noopener" class="police-beian">
                        <span class="police-icon" aria-hidden="true"></span>
                        <span class="police-text">京公网安备11000002000001号</span>
                    </a>
                
            </p>
        </section>
    </div>
</footer>


<script src="/static/kico.js"></script>
<script src="/static/hingle.js"></script>


<script>var hingle = new Paul_Hingle({"copyright":true,"night":true});</script>

<style>
.police-beian{display:inline-flex;align-items:center;gap:4px}
.police-icon{display:inline-block;width:16px;height:16px;background:#e91e63;border-radius:2px;opacity:.85}
/* 说明：如需官方警徽图标，可将 .police-icon 的 background 设置为图片：
   background:url('https://www.beian.gov.cn/img/ghs.png') no-repeat center/contain; */
</style>

  </body>
</html>
