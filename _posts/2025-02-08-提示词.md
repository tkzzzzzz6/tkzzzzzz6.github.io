
### 可参考的提示词（Prompts）

您可以将这些提示词组合或分步提供给AI，以生成文章的各个部分。

#### **角色设定与总体任务 (Master Prompt)**

> 你是一位资深的软件工程师和技术博主，擅长撰写清晰、易于理解的“手把手”教程。
>
> 我需要你帮我写一篇关于“**本地化部署DeepSeek模型**”的博客文章。
>
> **核心技术栈包括**：Ollama、DeepSeek-1.5B模型、Open WebUI。
> **目标平台**：主要是在Windows 11本地部署，其次是在Linux服务器上部署。
> **文章风格**：面向有一定基础的开发者，步骤清晰，配有命令代码和截图占位符 `![截图描述]`。
>
> **文章需要包含以下几个部分**：
>
> 1. 引言和准备工作（参考资料、实验目的）。
> 2. Windows下的详细部署流程：安装Ollama -> 拉取DeepSeek模型 -> 通过命令行和Open WebUI（pip和Docker两种方式）进行交互。
> 3. Linux服务器上的简化部署流程，指出与Windows的不同之处。
> 4. 一个总结，评价1.5B小模型的优缺点和适用场景。
>
> 现在，请先为我生成文章的**大纲**和**引言部分**。

#### **分步生成提示词 (Step-by-Step Prompts)**

**第1步：生成引言和准备工作**

> 根据我们之前定下的主题“本地化部署DeepSeek模型”，请为我撰写文章的**引言**、**参考资料**和**实验目的**部分。参考资料可以先用占位符链接。实验目的要清晰地列出我们计划完成的任务。

**第2步：生成Windows部署 - Ollama和模型部分**

> 接下来，请撰写“**在Windows本地部署**”的第一部分内容。
>
> 1. **下载并安装Ollama**：描述如何从 `ollama.com` 下载并安装Ollama，并为下载页面和安装过程各插入一个截图占位符。
> 2. **通过Ollama拉取DeepSeek模型**：说明我们将使用 `deepseek-r1:1.5b` 模型，提供 `ollama run` 命令，并附上一个查看更多版本的Ollama官网链接。最后插入一个命令成功执行的截图占位符。

**第3步：生成Windows部署 - 交互方式部分**

> 现在，请详细描述与本地模型交互的几种方式。
>
> 1. **终端回答**：简单描述这是最直接的方式，并插入一张终端对话的截图占位符。
> 2. **使用open-webui**：重点介绍这个方法。
>    - 先写一个“注意”块，提醒用户需要Python 3.11和Conda环境。
>    - 写一个子标题“**使用pip安装**”，提供创建conda环境、pip安装和启动服务的完整命令，并说明如何访问（`localhost:8080`）。插入UI截图占位符。
>    - 再写一个子标题“**使用docker安装**”，提供 `docker run` 命令，解释端口映射。说明如何访问（`localhost:3000`）。插入Docker运行状态和UI界面的截图占位符。

**第44步：生成Linux服务器部署部分**

> 请为我撰写“**linux服务器部署**”章节。
>
> - 开头说明这个过程和Windows类似。
> - 提供在Linux下安装Ollama的 `curl` 命令和 `sudo snap install ollama` 备用命令。
> - 简要列出后续的 `ollama run` 和 `docker run` 命令。
> - 特别提醒用户访问时需要使用服务器的公网IP。
> - 最后插入一张在Linux上部署成功并访问的截图占位符。

**第5步：生成总结部分**

> 最后，请为整篇文章撰写一个**总结**。评价一下像DeepSeek-1.5B这样的小参数模型的**优势**（资源占用、延迟）和**局限性**（生成能力）。根据这些特点，给出你的**最终建议**：这类模型适合什么场景（如边缘计算、基础任务），而对于高质量的生产需求，应该选择什么样的模型。
>
